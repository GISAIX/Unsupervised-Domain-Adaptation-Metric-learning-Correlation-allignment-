{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniruddha/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import numpy\n",
    "import PIL\n",
    "from PIL import Image\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "\n",
    "\n",
    "def euclidean_distance(x, y):\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def conc(vects):\n",
    "    x, y = vects\n",
    "    conc1 = concatenate([x,y])\n",
    "    return conc1\n",
    "\n",
    "def conc_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],32)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    x = y_pred[:,0:128]\n",
    "    y = y_pred[:,128:268]\n",
    "    y_pred1 = euclidean_distance(x,y)\n",
    "    p = x\n",
    "    q = y\n",
    "    p = K.clip(p, K.epsilon(), 1)\n",
    "    q = K.clip(q, K.epsilon(), 1)\n",
    "    #y_true1 = y_true[:,0]\n",
    "    #y_true1 = K.reshape(y_true1,(-1,))\n",
    "    #print(y_true1)\n",
    "    #tr_same = y_true[:,1]\n",
    "    #tr_same = K.reshape(tr_same, (-1,))\n",
    "    y_true1 = y_true\n",
    "    tr_same = K.round(y_true/3)\n",
    "    margin = 1\n",
    "    test = 0.001*K.sum(p*K.abs(K.log(p)-K.log(q)), axis=1)\n",
    "\n",
    "    return K.mean((1-tr_same)*(y_true1 * K.square(y_pred1) + (1 - y_true1) * K.square(K.maximum(margin - y_pred1, 0)))\n",
    "                 + (tr_same)*test)\n",
    "\n",
    "def triplet_loss(y_true, y_pred):\n",
    "    x = y_pred[:,0:32]\n",
    "    y = y_pred[:,32:64]\n",
    "    y_pred1 = euclidean_distance(x,y)\n",
    "    y_true1 = y_true\n",
    "    margin = 1\n",
    "    return K.mean(y_true1 * K.square(y_pred1) + (1 - y_true1) * K.square(K.maximum(margin - y_pred1, 0)))\n",
    "\n",
    "def coral_loss(y_true, y_pred):\n",
    "    x = y_pred[:,0:32]\n",
    "    y = y_pred[:,32:64]\n",
    "    n = 32.0\n",
    "    mul1 = K.dot(K.transpose(x),x)\n",
    "    one = x*0+1\n",
    "    mul2 = K.dot(K.transpose(one), x)\n",
    "    sub = K.dot(K.transpose(mul2), mul2)\n",
    "    source = (mul1 - (sub)/n)/(n-1)\n",
    "    #source = K.abs(source)\n",
    "    source = K.clip(source, K.epsilon(),10000)\n",
    "    #source1 = K.log(source)\n",
    "    \n",
    "    mul11 = K.dot(K.transpose(y),y)\n",
    "    mul21 = K.dot(K.transpose(one), y)\n",
    "    sub1 = K.dot(K.transpose(mul2), mul2)\n",
    "    n = float(n)\n",
    "    target = (mul11 - (sub1)/n)/(n-1)\n",
    "    #target = K.abs(target)\n",
    "    target = K.clip(target, K.epsilon(),10000)\n",
    "    #target1 = K.log(target)\n",
    "    \n",
    "    return (K.sum(K.dot((source-target),(source-target)))/(4*32.0))\n",
    "       \n",
    "    \n",
    "\n",
    "def create_pairs(x, digit_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(7)]) - 1\n",
    "    for d in range(7):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1,7)\n",
    "            dn = (d + inc) % 7\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "def create_addi_pairs(x, y):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    for i in range(0,1000):\n",
    "        k1 = random.randrange(0,x.shape[0])\n",
    "        for j in range(0,10):\n",
    "            k2 = random.randrange(0, y.shape[0])\n",
    "            pairs+= [[x[k1],y[k2]]]\n",
    "            labels += [3]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "             \n",
    "            \n",
    "def create_base_network():\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    seq = Sequential()\n",
    "    seq.add(Dense(64, input_shape=(64,), activation='relu'))\n",
    "    #seq.add(Dense(64, activation='relu'))\n",
    "    seq.add(Dense(32, activation='relu'))\n",
    "    seq.add(Dense(32, activation='relu'))\n",
    "    return seq\n",
    "\n",
    "\n",
    "def compute_accuracy(predictions, labels):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return labels[predictions.ravel() < 0.5].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1096, 715, 102)\n",
      "(1096, 715)\n",
      "(72933, 102)\n",
      "(72933,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniruddha/anaconda3/envs/tensorflow/lib/python3.5/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint16 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72933, 64)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('/home/aniruddha/deep-learning-projects/Siamese_Networks/Dataset/PaviaCentre.mat')\n",
    "arr = mat['pavia']\n",
    "arr = np.array(arr)\n",
    "print(arr.shape)\n",
    "\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat('/home/aniruddha/deep-learning-projects/Siamese_Networks/Dataset/PaviaCentre_gt.mat')\n",
    "arr1 = mat['pavia_gt']\n",
    "arr1 = np.array(arr1)\n",
    "print(arr1.shape)\n",
    "\n",
    "a=[]\n",
    "label=[]\n",
    "k=0\n",
    "for i in range(0,arr1.shape[0]):\n",
    "    for j in range(0,arr1[i].shape[0]):\n",
    "        a.append(arr[i][j])\n",
    "        label.append(arr1[i][j])\n",
    "        \n",
    "a=np.array(a)\n",
    "label=np.array(label)\n",
    "\n",
    "X_train=[]\n",
    "y_train=[]\n",
    "for i in range (0,a.shape[0]):\n",
    "    if(label[i]==2):\n",
    "        y_train.append(0)\n",
    "    if(label[i]==3):\n",
    "        y_train.append(1)\n",
    "    if(label[i]==4):\n",
    "        y_train.append(2)\n",
    "    if(label[i]==5):\n",
    "        y_train.append(3)\n",
    "    if(label[i]==7):\n",
    "        y_train.append(4)\n",
    "    if(label[i]==8):\n",
    "        y_train.append(5)\n",
    "    if(label[i]==9):\n",
    "        y_train.append(6)\n",
    "    if (label[i]==2 or label[i]==3 or label[i]==4 or label[i]==5 or label[i]==7 or label[i]==8 or label[i]==9):\n",
    "        X_train.append(a[i])\n",
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state = 0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=64)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(label.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(610, 340)\n",
      "(207400, 103)\n",
      "(207400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniruddha/anaconda3/envs/tensorflow/lib/python3.5/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint16 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39332, 64)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('/home/aniruddha/deep-learning-projects/Siamese_Networks/Dataset/PaviaU.mat')\n",
    "arr = mat['paviaU']\n",
    "arr = np.array(arr)\n",
    "\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat('/home/aniruddha/deep-learning-projects/Siamese_Networks/Dataset/PaviaU_gt.mat')\n",
    "arr1 = mat['paviaU_gt']\n",
    "arr1 = np.array(arr1)\n",
    "print(arr1.shape)\n",
    "\n",
    "a=[]\n",
    "label=[]\n",
    "k=0\n",
    "for i in range(0,arr1.shape[0]):\n",
    "    for j in range(0,arr1[i].shape[0]):\n",
    "        a.append(arr[i][j])\n",
    "        label.append(arr1[i][j])\n",
    "        \n",
    "a=np.array(a)\n",
    "label=np.array(label)\n",
    "print(a.shape)\n",
    "print(label.shape)\n",
    "\n",
    "X_train1=[]\n",
    "y_train1=[]\n",
    "for i in range (0,a.shape[0]):\n",
    "    if(label[i]==4):\n",
    "        y_train1.append(0)\n",
    "    if(label[i]==1):\n",
    "        y_train1.append(1)\n",
    "    if(label[i]==8):\n",
    "        y_train1.append(2)\n",
    "    if(label[i]==7):\n",
    "        y_train1.append(3)\n",
    "    if(label[i]==9):\n",
    "        y_train1.append(4)\n",
    "    if(label[i]==2):\n",
    "        y_train1.append(5)\n",
    "    if(label[i]==6):\n",
    "        y_train1.append(6)\n",
    "    if (label[i]==4 or label[i]==1 or label[i]==8 or label[i]==7 or label[i]==9 or label[i]==2 or label[i]==6):\n",
    "        X_train1.append(a[i])\n",
    "X_train1=np.array(X_train1)\n",
    "y_train1=np.array(y_train1)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X_train1, y_train1 = shuffle(X_train1, y_train1, random_state = 0)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train1 = StandardScaler().fit_transform(X_train1)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=64)\n",
    "X_train1 = pca.fit_transform(X_train1)\n",
    "print(X_train1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.423585702771796\n",
      "104.56701566525479\n"
     ]
    }
   ],
   "source": [
    "print(X_train.max())\n",
    "print(X_train1.max())\n",
    "X_train=X_train.astype('float32')\n",
    "X_train1=X_train1.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-19.61208\n",
      "-19.46586\n"
     ]
    }
   ],
   "source": [
    "print(X_train.min())\n",
    "print(X_train1.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train/100\n",
    "X_train1=X_train1/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39332, 64)\n",
      "(22933, 64)\n"
     ]
    }
   ],
   "source": [
    "X_test=X_train[50000:72933,:]\n",
    "y_test=y_train[50000:72933]\n",
    "X_train=X_train[0:50000,:]\n",
    "y_train=y_train[0:50000]\n",
    "\n",
    "print(X_train1.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47423583\n",
      "1.0456702\n",
      "0.36481896\n",
      "-0.19607832\n",
      "-0.1946586\n"
     ]
    }
   ],
   "source": [
    "print((X_train).max())\n",
    "print(abs(X_train1).max())\n",
    "print(abs(X_test).max())\n",
    "print(X_train.min())\n",
    "print(X_train1.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_indices = [np.where(y_train1 == i)[0] for i in range(7)]\n",
    "tr_pairs, tr_y = create_pairs(X_train1, digit_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr1_pairs, tr1_y = create_addi_pairs(X_train1, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13244, 2, 64)\n",
      "(10000, 2, 64)\n"
     ]
    }
   ],
   "source": [
    "print(tr_pairs.shape)\n",
    "print(tr1_pairs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 64)\n",
      "(?, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniruddha/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"la...)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# network definition\n",
    "input_dim=X_train.shape[1:]\n",
    "base_network = create_base_network()\n",
    "\n",
    "input_a = Input(shape=input_dim)\n",
    "input_b = Input(shape=input_dim)\n",
    "\n",
    "#input_a=K.reshape(input_a,(28,28,1))\n",
    "#input_b=K.reshape(input_b,(28,28,1))\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "print(input_b.shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(conc, output_shape=conc_shape)([processed_a, processed_b])\n",
    "print(distance.shape)\n",
    "\n",
    "model = Model(input=[input_a, input_b], output=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniruddha/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_model = Model(input = input_a, output = processed_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"191pt\" viewBox=\"0.00 0.00 276.00 191.00\" width=\"276pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 187)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-187 272,-187 272,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139847398179784 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139847398179784</title>\n",
       "<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 125,-182.5 125,-146.5 0,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-160.8\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139845857956808 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139845857956808</title>\n",
       "<polygon fill=\"none\" points=\"59,-73.5 59,-109.5 208,-109.5 208,-73.5 59,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133.5\" y=\"-87.8\">sequential_1: Sequential</text>\n",
       "</g>\n",
       "<!-- 139847398179784&#45;&gt;139845857956808 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139847398179784-&gt;139845857956808</title>\n",
       "<path d=\"M79.6871,-146.313C88.5826,-137.417 99.5906,-126.409 109.328,-116.672\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"111.875,-119.075 116.471,-109.529 106.925,-114.125 111.875,-119.075\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139845849953056 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139845849953056</title>\n",
       "<polygon fill=\"none\" points=\"143,-146.5 143,-182.5 268,-182.5 268,-146.5 143,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-160.8\">input_2: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139845849953056&#45;&gt;139845857956808 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139845849953056-&gt;139845857956808</title>\n",
       "<path d=\"M188.071,-146.313C179.05,-137.417 167.887,-126.409 158.012,-116.672\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"160.347,-114.058 150.769,-109.529 155.432,-119.042 160.347,-114.058\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139845850021616 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139845850021616</title>\n",
       "<polygon fill=\"none\" points=\"72,-0.5 72,-36.5 195,-36.5 195,-0.5 72,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133.5\" y=\"-14.8\">lambda_1: Lambda</text>\n",
       "</g>\n",
       "<!-- 139845857956808&#45;&gt;139845850021616 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139845857956808-&gt;139845850021616</title>\n",
       "<path d=\"M133.5,-73.3129C133.5,-65.2895 133.5,-55.5475 133.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"137,-46.5288 133.5,-36.5288 130,-46.5289 137,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13244, 64)\n",
      "(13244, 64)\n",
      "(13244,)\n"
     ]
    }
   ],
   "source": [
    "print(tr_pairs[:,0].shape)\n",
    "print(tr_pairs[:,1].shape)\n",
    "print(tr_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniruddha/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:7: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 116us/step - loss: 0.1365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniruddha/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:9: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 60us/step - loss: 2.7817e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 54us/step - loss: 0.0813\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 83us/step - loss: 0.0000e+00\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 94us/step - loss: 0.0742\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 65us/step - loss: 3.9243e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 62us/step - loss: 0.0702\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 67us/step - loss: 0.0000e+00\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 63us/step - loss: 0.0669\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 74us/step - loss: 0.0000e+00\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 64us/step - loss: 0.0646\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 75us/step - loss: 0.0000e+00\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 68us/step - loss: 0.0622\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 79us/step - loss: 0.0000e+00\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 71us/step - loss: 0.0605\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 85us/step - loss: 0.0000e+00\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 76us/step - loss: 0.0590\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 88us/step - loss: 0.0000e+00\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 75us/step - loss: 0.0578\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 94us/step - loss: 2.4644e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 84us/step - loss: 0.0567\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 97us/step - loss: 0.0000e+00\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 83us/step - loss: 0.0555\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 101us/step - loss: 0.0000e+00\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 85us/step - loss: 0.0547\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 101us/step - loss: 0.0000e+00\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 89us/step - loss: 0.0536\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 111us/step - loss: 0.0000e+00\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 92us/step - loss: 0.0527\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 113us/step - loss: 1.3428e-12\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 98us/step - loss: 0.0521\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 115us/step - loss: 0.0000e+00\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 99us/step - loss: 0.0515\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 126us/step - loss: 0.0000e+00\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 102us/step - loss: 0.0505\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 124us/step - loss: 5.3016e-10\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 107us/step - loss: 0.0498\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 127us/step - loss: 2.8138e-10\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 108us/step - loss: 0.0491\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 137us/step - loss: 1.6954e-10\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 112us/step - loss: 0.0483\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 136us/step - loss: 5.8697e-10\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 113us/step - loss: 0.0485\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 140us/step - loss: 1.5960e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 116us/step - loss: 0.0477\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 143us/step - loss: 0.0000e+00\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 120us/step - loss: 0.0467\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 1.6647e-12\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 121us/step - loss: 0.0466\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 154us/step - loss: 3.2941e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 128us/step - loss: 0.0460\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 158us/step - loss: 9.1797e-10\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 126us/step - loss: 0.0455\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 158us/step - loss: 0.0000e+00\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 133us/step - loss: 0.0449\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 163us/step - loss: 9.1548e-12\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 135us/step - loss: 0.0441\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 168us/step - loss: 6.1664e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 138us/step - loss: 0.0440\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 169us/step - loss: 2.4992e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 140us/step - loss: 0.0434\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 177us/step - loss: 2.2205e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 143us/step - loss: 0.0427\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 178us/step - loss: 2.8711e-10\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 144us/step - loss: 0.0421\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 187us/step - loss: 2.7359e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 151us/step - loss: 0.0421\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 215us/step - loss: 2.0935e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 153us/step - loss: 0.0418\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 190us/step - loss: 2.3083e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 158us/step - loss: 0.0410\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 193us/step - loss: 3.3774e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 157us/step - loss: 0.0408\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 196us/step - loss: 1.2839e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 163us/step - loss: 0.0404\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 205us/step - loss: 1.2848e-10\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 162us/step - loss: 0.0395\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 209us/step - loss: 1.3242e-11\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 167us/step - loss: 0.0394\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 211us/step - loss: 5.9183e-11\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 172us/step - loss: 0.0387\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 215us/step - loss: 1.5615e-12\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 172us/step - loss: 0.0387\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 227us/step - loss: 1.9482e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 176us/step - loss: 0.0384\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 223us/step - loss: 4.1519e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 180us/step - loss: 0.0384\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 229us/step - loss: 4.4625e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 182us/step - loss: 0.0373\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 231us/step - loss: 1.8370e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 184us/step - loss: 0.0373\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 235us/step - loss: 3.7043e-10\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 189us/step - loss: 0.0371\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 236us/step - loss: 2.6762e-06\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13244/13244 [==============================] - 2s 188us/step - loss: 0.0370\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 241us/step - loss: 3.4150e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 3s 197us/step - loss: 0.0364\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 246us/step - loss: 4.7893e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 3s 202us/step - loss: 0.0362\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 247us/step - loss: 1.0595e-08\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "from keras import optimizers\n",
    "#sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "rms = RMSprop()\n",
    "for i in range(0,50):\n",
    "     model.compile(loss=triplet_loss, optimizer=rms)\n",
    "     model.fit([tr_pairs[:,0], tr_pairs[:, 1]], tr_y, batch_size=64, nb_epoch=1)\n",
    "     model.compile(loss=coral_loss, optimizer=rms)\n",
    "     model.fit([tr1_pairs[:,0], tr1_pairs[:, 1]], tr1_y, batch_size=64, nb_epoch=1)\n",
    "     \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36693066 0.57964516 0.44073877 0.         0.58465564 0.4737161\n",
      " 0.36650056 0.05872609 0.05423261 0.         0.53869486 0.\n",
      " 0.04125543 0.38844705 0.         0.62887233 0.         0.05156846\n",
      " 0.24222128 0.         0.4046552  0.6289208  0.613619   0.3876175\n",
      " 0.46294853 0.42484802 0.         0.         0.         0.049803\n",
      " 0.4148853  0.56561536]\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "processed=test_model.predict(X_train1)\n",
    "print(processed[100])\n",
    "print(processed[100].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 7)\n",
      "(39332, 7)\n",
      "(22933, 7)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "y_tr = np_utils.to_categorical(y_train)\n",
    "y_tr1 = np_utils.to_categorical(y_train1)\n",
    "y_te = np_utils.to_categorical(y_test)\n",
    "num_classes = 7\n",
    "print(y_tr.shape)\n",
    "print(y_tr1.shape)\n",
    "print(y_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pixels = 32\n",
    "# define baseline model\n",
    "def baseline_model1():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(32, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32)\n",
      "(39332, 32)\n",
      "(22933, 32)\n"
     ]
    }
   ],
   "source": [
    "processed_train = test_model.predict(X_train)\n",
    "processed_train1 = test_model.predict(X_train1)\n",
    "processed_test = test_model.predict(X_test)\n",
    "print(processed_train.shape)\n",
    "print(processed_train1.shape)\n",
    "print(processed_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39332 samples, validate on 50000 samples\n",
      "Epoch 1/100\n",
      "39332/39332 [==============================] - 4s 93us/step - loss: 1.1577 - acc: 0.6155 - val_loss: 2.1966 - val_acc: 0.3994\n",
      "Epoch 2/100\n",
      "39332/39332 [==============================] - 2s 39us/step - loss: 0.4371 - acc: 0.8619 - val_loss: 3.1616 - val_acc: 0.4114\n",
      "Epoch 3/100\n",
      "39332/39332 [==============================] - 2s 57us/step - loss: 0.3025 - acc: 0.9041 - val_loss: 3.6232 - val_acc: 0.4051\n",
      "Epoch 4/100\n",
      "39332/39332 [==============================] - 2s 43us/step - loss: 0.2800 - acc: 0.9056 - val_loss: 3.8475 - val_acc: 0.4244\n",
      "Epoch 5/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.2626 - acc: 0.9067 - val_loss: 4.2401 - val_acc: 0.3861\n",
      "Epoch 6/100\n",
      "39332/39332 [==============================] - 1s 35us/step - loss: 0.2405 - acc: 0.9205 - val_loss: 4.3693 - val_acc: 0.3926\n",
      "Epoch 7/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.2258 - acc: 0.9264 - val_loss: 4.3580 - val_acc: 0.4074\n",
      "Epoch 8/100\n",
      "39332/39332 [==============================] - 1s 29us/step - loss: 0.2184 - acc: 0.9283 - val_loss: 4.3808 - val_acc: 0.4001\n",
      "Epoch 9/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.2135 - acc: 0.9303 - val_loss: 4.4621 - val_acc: 0.3749\n",
      "Epoch 10/100\n",
      "39332/39332 [==============================] - 1s 32us/step - loss: 0.2112 - acc: 0.9323 - val_loss: 4.4524 - val_acc: 0.3829\n",
      "Epoch 11/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.2087 - acc: 0.9329 - val_loss: 4.3585 - val_acc: 0.4110\n",
      "Epoch 12/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.2076 - acc: 0.9344 - val_loss: 4.4449 - val_acc: 0.3721\n",
      "Epoch 13/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.2063 - acc: 0.9347 - val_loss: 4.3419 - val_acc: 0.3970\n",
      "Epoch 14/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.2048 - acc: 0.9350 - val_loss: 4.4089 - val_acc: 0.3644\n",
      "Epoch 15/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.2042 - acc: 0.9352 - val_loss: 4.2926 - val_acc: 0.3671\n",
      "Epoch 16/100\n",
      "39332/39332 [==============================] - 1s 29us/step - loss: 0.2030 - acc: 0.9361 - val_loss: 4.2452 - val_acc: 0.3969\n",
      "Epoch 17/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.2018 - acc: 0.9357 - val_loss: 4.2186 - val_acc: 0.4008\n",
      "Epoch 18/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.2010 - acc: 0.9365 - val_loss: 4.2347 - val_acc: 0.3913\n",
      "Epoch 19/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.2010 - acc: 0.9362 - val_loss: 4.1968 - val_acc: 0.4115\n",
      "Epoch 20/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.2008 - acc: 0.9368 - val_loss: 4.3929 - val_acc: 0.3412\n",
      "Epoch 21/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1987 - acc: 0.9365 - val_loss: 4.2065 - val_acc: 0.4030\n",
      "Epoch 22/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1980 - acc: 0.9368 - val_loss: 4.1717 - val_acc: 0.4033\n",
      "Epoch 23/100\n",
      "39332/39332 [==============================] - 1s 33us/step - loss: 0.1974 - acc: 0.9376 - val_loss: 4.2828 - val_acc: 0.3702\n",
      "Epoch 24/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1975 - acc: 0.9372 - val_loss: 4.1602 - val_acc: 0.4194\n",
      "Epoch 25/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1965 - acc: 0.9381 - val_loss: 4.2818 - val_acc: 0.3735\n",
      "Epoch 26/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1957 - acc: 0.9376 - val_loss: 4.2525 - val_acc: 0.3866\n",
      "Epoch 27/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1941 - acc: 0.9384 - val_loss: 4.2531 - val_acc: 0.3919\n",
      "Epoch 28/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1937 - acc: 0.9386 - val_loss: 4.1936 - val_acc: 0.3798\n",
      "Epoch 29/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1929 - acc: 0.9389 - val_loss: 4.1701 - val_acc: 0.4154\n",
      "Epoch 30/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1919 - acc: 0.9394 - val_loss: 4.1669 - val_acc: 0.4060\n",
      "Epoch 31/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1911 - acc: 0.9385 - val_loss: 4.2519 - val_acc: 0.3672\n",
      "Epoch 32/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1904 - acc: 0.9390 - val_loss: 4.2291 - val_acc: 0.3788\n",
      "Epoch 33/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1895 - acc: 0.9393 - val_loss: 4.2096 - val_acc: 0.3735\n",
      "Epoch 34/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1894 - acc: 0.9396 - val_loss: 4.1761 - val_acc: 0.3962\n",
      "Epoch 35/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1889 - acc: 0.9400 - val_loss: 4.1644 - val_acc: 0.3973\n",
      "Epoch 36/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1872 - acc: 0.9400 - val_loss: 4.2171 - val_acc: 0.3893\n",
      "Epoch 37/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1875 - acc: 0.9397 - val_loss: 4.1188 - val_acc: 0.4069\n",
      "Epoch 38/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1864 - acc: 0.9399 - val_loss: 4.1175 - val_acc: 0.3987\n",
      "Epoch 39/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1850 - acc: 0.9405 - val_loss: 4.1986 - val_acc: 0.3561\n",
      "Epoch 40/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1845 - acc: 0.9400 - val_loss: 4.1780 - val_acc: 0.3693\n",
      "Epoch 41/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1839 - acc: 0.9407 - val_loss: 4.0596 - val_acc: 0.4207\n",
      "Epoch 42/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1822 - acc: 0.9419 - val_loss: 4.1334 - val_acc: 0.3759\n",
      "Epoch 43/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1812 - acc: 0.9415 - val_loss: 4.0548 - val_acc: 0.4093\n",
      "Epoch 44/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1808 - acc: 0.9404 - val_loss: 4.0969 - val_acc: 0.3501\n",
      "Epoch 45/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1803 - acc: 0.9411 - val_loss: 4.0703 - val_acc: 0.3855\n",
      "Epoch 46/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1799 - acc: 0.9410 - val_loss: 4.0542 - val_acc: 0.3998\n",
      "Epoch 47/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1789 - acc: 0.9411 - val_loss: 4.1137 - val_acc: 0.3669\n",
      "Epoch 48/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1782 - acc: 0.9412 - val_loss: 4.0984 - val_acc: 0.3592\n",
      "Epoch 49/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1786 - acc: 0.9412 - val_loss: 4.0635 - val_acc: 0.3766\n",
      "Epoch 50/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1778 - acc: 0.9418 - val_loss: 4.0455 - val_acc: 0.4048\n",
      "Epoch 51/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1771 - acc: 0.9419 - val_loss: 4.0074 - val_acc: 0.4002\n",
      "Epoch 52/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1772 - acc: 0.9421 - val_loss: 4.1040 - val_acc: 0.3907\n",
      "Epoch 53/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1771 - acc: 0.9411 - val_loss: 4.0448 - val_acc: 0.3920\n",
      "Epoch 54/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1763 - acc: 0.9419 - val_loss: 4.0381 - val_acc: 0.3797\n",
      "Epoch 55/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1766 - acc: 0.9418 - val_loss: 4.0974 - val_acc: 0.3775\n",
      "Epoch 56/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1768 - acc: 0.9408 - val_loss: 4.1759 - val_acc: 0.3528\n",
      "Epoch 57/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1767 - acc: 0.9423 - val_loss: 4.0275 - val_acc: 0.3847\n",
      "Epoch 58/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1755 - acc: 0.9424 - val_loss: 4.0988 - val_acc: 0.3696\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1757 - acc: 0.9418 - val_loss: 4.0063 - val_acc: 0.3951\n",
      "Epoch 60/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1755 - acc: 0.9425 - val_loss: 4.0440 - val_acc: 0.3929\n",
      "Epoch 61/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1750 - acc: 0.9414 - val_loss: 4.1486 - val_acc: 0.3481\n",
      "Epoch 62/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1752 - acc: 0.9424 - val_loss: 4.2142 - val_acc: 0.3516\n",
      "Epoch 63/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1748 - acc: 0.9423 - val_loss: 4.0947 - val_acc: 0.3809\n",
      "Epoch 64/100\n",
      "39332/39332 [==============================] - 2s 39us/step - loss: 0.1745 - acc: 0.9427 - val_loss: 4.0286 - val_acc: 0.4074\n",
      "Epoch 65/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1744 - acc: 0.9421 - val_loss: 4.1709 - val_acc: 0.3593\n",
      "Epoch 66/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1740 - acc: 0.9430 - val_loss: 4.1188 - val_acc: 0.3704\n",
      "Epoch 67/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1750 - acc: 0.9423 - val_loss: 4.1004 - val_acc: 0.3788\n",
      "Epoch 68/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1742 - acc: 0.9417 - val_loss: 4.2083 - val_acc: 0.3325\n",
      "Epoch 69/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1750 - acc: 0.9416 - val_loss: 4.1286 - val_acc: 0.3868\n",
      "Epoch 70/100\n",
      "39332/39332 [==============================] - 1s 35us/step - loss: 0.1739 - acc: 0.9422 - val_loss: 4.0965 - val_acc: 0.3912\n",
      "Epoch 71/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1742 - acc: 0.9422 - val_loss: 4.1076 - val_acc: 0.3912\n",
      "Epoch 72/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1745 - acc: 0.9422 - val_loss: 4.1882 - val_acc: 0.3812\n",
      "Epoch 73/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1733 - acc: 0.9431 - val_loss: 4.1035 - val_acc: 0.3949\n",
      "Epoch 74/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1734 - acc: 0.9422 - val_loss: 4.1472 - val_acc: 0.3930\n",
      "Epoch 75/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1735 - acc: 0.9423 - val_loss: 4.0696 - val_acc: 0.4048\n",
      "Epoch 76/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1733 - acc: 0.9426 - val_loss: 4.0706 - val_acc: 0.4004\n",
      "Epoch 77/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1731 - acc: 0.9426 - val_loss: 4.1293 - val_acc: 0.4173\n",
      "Epoch 78/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1732 - acc: 0.9424 - val_loss: 4.1209 - val_acc: 0.3910\n",
      "Epoch 79/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1733 - acc: 0.9427 - val_loss: 4.1714 - val_acc: 0.3645\n",
      "Epoch 80/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1736 - acc: 0.9430 - val_loss: 4.1391 - val_acc: 0.3830\n",
      "Epoch 81/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1729 - acc: 0.9424 - val_loss: 4.1838 - val_acc: 0.3820\n",
      "Epoch 82/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1725 - acc: 0.9427 - val_loss: 4.2290 - val_acc: 0.3844\n",
      "Epoch 83/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1727 - acc: 0.9423 - val_loss: 4.2352 - val_acc: 0.3503\n",
      "Epoch 84/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1723 - acc: 0.9437 - val_loss: 4.1411 - val_acc: 0.3975\n",
      "Epoch 85/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1731 - acc: 0.9424 - val_loss: 4.2380 - val_acc: 0.3703\n",
      "Epoch 86/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1721 - acc: 0.9428 - val_loss: 4.1915 - val_acc: 0.3695\n",
      "Epoch 87/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1720 - acc: 0.9426 - val_loss: 4.1869 - val_acc: 0.3825\n",
      "Epoch 88/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1725 - acc: 0.9435 - val_loss: 4.2052 - val_acc: 0.3903\n",
      "Epoch 89/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1726 - acc: 0.9429 - val_loss: 4.1373 - val_acc: 0.3934\n",
      "Epoch 90/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1722 - acc: 0.9432 - val_loss: 4.0931 - val_acc: 0.4123\n",
      "Epoch 91/100\n",
      "39332/39332 [==============================] - 1s 33us/step - loss: 0.1730 - acc: 0.9426 - val_loss: 4.1453 - val_acc: 0.3929\n",
      "Epoch 92/100\n",
      "39332/39332 [==============================] - 1s 35us/step - loss: 0.1717 - acc: 0.9433 - val_loss: 4.2322 - val_acc: 0.3664\n",
      "Epoch 93/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1723 - acc: 0.9432 - val_loss: 4.2400 - val_acc: 0.3895\n",
      "Epoch 94/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1721 - acc: 0.9433 - val_loss: 4.2198 - val_acc: 0.3943\n",
      "Epoch 95/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1723 - acc: 0.9435 - val_loss: 4.2536 - val_acc: 0.3807\n",
      "Epoch 96/100\n",
      "39332/39332 [==============================] - 1s 30us/step - loss: 0.1721 - acc: 0.9439 - val_loss: 4.2063 - val_acc: 0.3970\n",
      "Epoch 97/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1717 - acc: 0.9440 - val_loss: 4.2832 - val_acc: 0.3465\n",
      "Epoch 98/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1712 - acc: 0.9439 - val_loss: 4.1662 - val_acc: 0.4080\n",
      "Epoch 99/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1713 - acc: 0.9434 - val_loss: 4.1882 - val_acc: 0.4162\n",
      "Epoch 100/100\n",
      "39332/39332 [==============================] - 1s 31us/step - loss: 0.1716 - acc: 0.9433 - val_loss: 4.1937 - val_acc: 0.3929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2fbf22bb00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# build the model\n",
    "model1 = baseline_model1()\n",
    "# Fit the model\n",
    "model1.fit(processed_train1, y_tr1, validation_data=(processed_train, y_tr), epochs=100, batch_size=128, verbose=1)\n",
    "# Final evaluation of the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39332/39332 [==============================] - 2s 44us/step\n",
      "32933/32933 [==============================] - 1s 44us/step\n",
      "* Accuracy on training set: 94.32%\n",
      "* Accuracy on test set: 42.78%\n"
     ]
    }
   ],
   "source": [
    "#32 output dim new\n",
    "#CORAL\n",
    "# acc 45.86\n",
    "scores_train = model1.evaluate(processed_train1, y_tr1, verbose=1)\n",
    "scores_test = model1.evaluate(processed_test, y_te, verbose=1)\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * scores_train[1]))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * scores_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
