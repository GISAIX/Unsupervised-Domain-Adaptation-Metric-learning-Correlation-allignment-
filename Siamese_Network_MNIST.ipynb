{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniruddha/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniruddha/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['sqrt']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.layers.python.layers import initializers\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "get_ipython().magic('matplotlib inline')\n",
    "get_ipython().magic('pylab inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(mnist.test.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils# fix random seed for reproducibility\n",
    "y_test = np_utils.to_categorical(mnist.test.labels)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "logs_path = './tensorflow_logs/mnist_metrics'\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 28*28 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "margin = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    x_left = tf.placeholder(tf.float32, shape=[None, n_input], name='InputDataLeft')\n",
    "    x_right = tf.placeholder(tf.float32, shape=[None, n_input], name='InputDataRight')\n",
    "    label = tf.placeholder(tf.float32, shape=[None, 1], name='LabelData') # 0 if the same, 1 is different\n",
    "\n",
    "    x_image_left = x_left\n",
    "    x_image_right = x_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # def NN(inputs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfNN(x, weights, biases):\n",
    "    x = tf.scalar_mul(1.0/256.0, x)\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['w3']), biases['b3'])\n",
    "    out_layer = tf.add(tf.matmul(layer_3, weights['w4']), biases['b4'])\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Store layers weight & bias\n",
    "    #tf.random_uniform(\n",
    "    #shape,\n",
    "    #minval=0,\n",
    "    #maxval=None,\n",
    "    #dtype=tf.float32,\n",
    "    #seed=None,\n",
    "    #name=None\n",
    "    #)\n",
    "    weights = {\n",
    "    'w1': tf.Variable(tf.random_uniform([n_input, n_hidden_1], minval=-4*np.sqrt(6.0/(n_input + n_hidden_1)), maxval=4*np.sqrt(6.0/(n_input + n_hidden_1))), name='W1'),\n",
    "    'w2': tf.Variable(tf.random_uniform([n_hidden_1, n_hidden_2], minval=-4*np.sqrt(6.0/(n_hidden_1 + n_hidden_2)), maxval=4*np.sqrt(6.0/(n_hidden_1 + n_hidden_2))), name='W2'),\n",
    "    'w3': tf.Variable(tf.random_uniform([n_hidden_2, n_classes], minval=-4*np.sqrt(6.0/(n_hidden_2 + n_classes)), maxval=4*np.sqrt(6.0/(n_hidden_2 + n_classes))), name='W3'),\n",
    "    'w4': tf.Variable(tf.random_uniform([n_classes, n_classes], minval=-4*np.sqrt(6.0/(n_classes + 2)), maxval=4*np.sqrt(6.0/(n_classes + 2))), name='W4')\n",
    "    }\n",
    "    biases = {\n",
    "    'b1': tf.Variable(tf.truncated_normal([n_hidden_1]) / sqrt(n_hidden_1), name='b1'),\n",
    "    'b2': tf.Variable(tf.truncated_normal([n_hidden_2]) / sqrt(n_hidden_2), name='b2'),\n",
    "    'b3': tf.Variable(tf.truncated_normal([n_classes]) / sqrt(n_classes), name='b3'),\n",
    "    'b4': tf.Variable(tf.truncated_normal([n_classes]) / sqrt(n_classes), name='b4')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('Model'):\n",
    "    # Model\n",
    "    pred_left = tfNN(x_image_left, weights, biases)\n",
    "    pred_right = tfNN(x_image_right, weights, biases)\n",
    "    with tf.name_scope('Loss'):\n",
    "        d = tf.reduce_sum(tf.square(tf.subtract(pred_left, pred_right)), 1, keep_dims=True)\n",
    "    d_sqrt = tf.sqrt(d)\n",
    "    loss = label * tf.square(tf.maximum(0.0, margin - d_sqrt)) + (1 - label) * d\n",
    "    loss = 0.5 * tf.reduce_mean(loss)\n",
    "\n",
    "    with tf.name_scope('AdamOptimizer'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Initializing the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    # Create a summary to monitor cost tensor\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "    # Merge all summaries into a single op\n",
    "    merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss = 0.064200653\n",
      "Epoch: 0002 loss = 0.056520799\n",
      "Epoch: 0003 loss = 0.051354025\n",
      "Epoch: 0004 loss = 0.048397793\n",
      "Epoch: 0005 loss = 0.046401696\n",
      "Epoch: 0006 loss = 0.044863890\n",
      "Epoch: 0007 loss = 0.042009174\n",
      "Epoch: 0008 loss = 0.041419002\n",
      "Epoch: 0009 loss = 0.040068994\n",
      "Epoch: 0010 loss = 0.038715607\n",
      "Epoch: 0011 loss = 0.037500448\n",
      "Epoch: 0012 loss = 0.038650912\n",
      "Epoch: 0013 loss = 0.036761576\n",
      "Epoch: 0014 loss = 0.036632265\n",
      "Epoch: 0015 loss = 0.035978339\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # Launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "    # op to write logs to Tensorboard\n",
    "#summary_writer = tf.train.SummaryWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "    # Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    avg_loss = 0.0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        left_batch_xs, left_batch_ys = mnist.train.next_batch(batch_size)\n",
    "        right_batch_xs, right_batch_ys = mnist.train.next_batch(batch_size)\n",
    "        labels = np.zeros((batch_size, 1))\n",
    "        for l in range(batch_size):\n",
    "            if left_batch_ys[l] == right_batch_ys[l]:\n",
    "                labels[l, 0] = 0.0\n",
    "            else:\n",
    "                labels[l, 0] = 1.0\n",
    "        _, l, summary = sess.run([optimizer, loss, merged_summary_op],\n",
    "                                 feed_dict = {\n",
    "                                              x_left: left_batch_xs, \n",
    "                                              x_right: right_batch_xs,\n",
    "                                              label: labels,\n",
    "                                             })\n",
    "        # Write logs at every iteration\n",
    "        #summary_writer.add_summary(summary, epoch * total_batch + i)\n",
    "        # Compute average loss\n",
    "        avg_loss += l / total_batch\n",
    "    # Display logs per epoch step\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        print (\"Epoch:\", '%04d' % (epoch+1), \"loss =\", \"{:.9f}\".format(avg_loss))\n",
    "\n",
    "   # print (\"Optimization Finished!\")\n",
    "\n",
    "    #print (\"Run the command line:\\n\"       \"--> tensorboard --logdir=./tensorflow_logs \"       \"\\nThen open http://0.0.0.0:6006/ into your web browser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(left_batch_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Test model\n",
    "    # Calculate accuracy\n",
    "    test_xs, test_ys = mnist.train.next_batch(5000)\n",
    "    ans = sess.run([pred_left], feed_dict = { x_left: test_xs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.8381114   1.5780729  -5.345134   ... -4.421591   -2.2878385\n",
      "   5.9426293 ]\n",
      " [-0.36738443  1.329838   -5.9633474  ... -4.7710605  -2.1976\n",
      "   5.7436905 ]\n",
      " [-0.5971389   1.3976626  -5.178005   ... -4.494561   -2.1893253\n",
      "   5.855554  ]\n",
      " ...\n",
      " [-0.678532    1.5239226  -6.085644   ... -4.696464   -2.5387137\n",
      "   6.013779  ]\n",
      " [-0.83715725  1.3510245  -5.612461   ... -4.329441   -2.1274076\n",
      "   5.6156793 ]\n",
      " [-0.2918554   1.6776863  -5.1012573  ... -4.5307336  -2.5024292\n",
      "   5.966328  ]]\n",
      "5000\n",
      "[0 3 0 ... 2 6 0]\n"
     ]
    }
   ],
   "source": [
    "ans = ans[0]\n",
    "print(ans)\n",
    "print(len(ans))\n",
    "print(test_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "    # Test model\n",
    "    # Calculate accuracy\n",
    "    test_xs, test_ys = mnist.train.next_batch(5000)\n",
    "    ans = sess.run([pred_left], feed_dict = { x_left: test_xs})\n",
    "    print(test_xs)\n",
    "    print(test_ys[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(test_ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5025579   1.2206059  -5.509441   ... -4.2842298  -2.399009\n",
      "   5.7110767 ]\n",
      " [-0.59680027  1.4676498  -5.4196453  ... -4.032259   -2.2151098\n",
      "   5.8430624 ]\n",
      " [-0.5401863   1.3085862  -5.9583898  ... -4.869337   -2.2229967\n",
      "   5.722969  ]\n",
      " ...\n",
      " [-0.60106736  1.6431131  -6.0293403  ... -4.65068    -2.279252\n",
      "   5.9227953 ]\n",
      " [-0.46306723  1.3849088  -5.3485694  ... -4.108453   -2.1779695\n",
      "   5.9388523 ]\n",
      " [-0.9671508   1.3879946  -5.4602695  ... -4.5797334  -2.162062\n",
      "   5.621673  ]]\n"
     ]
    }
   ],
   "source": [
    "print(ans[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4add312eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_data(features,labels,axis,alpha=1.0):\n",
    "    # separate features according to their class\n",
    "    X0,X1,X2,X3,X4,X5,X6,X7,X8,X9 = features[labels==0], features[labels==1], features[labels==2], features[labels==3], features[labels==4], features[labels==5], features[labels==6], features[labels==7], features[labels==8], features[labels==9]\n",
    "    \n",
    "    # class 0 data\n",
    "    axis.plot(X0[:,0], X0[:,1], 'o', color='green', markersize=1, alpha=alpha)\n",
    "    # class 1 data\n",
    "    axis.plot(X1[:,0], X1[:,1], 'o', color='red', markersize=1, alpha=alpha)\n",
    "    # class 2 data\n",
    "    axis.plot(X2[:,0], X2[:,1], 'o', color='blue', markersize=1, alpha=alpha)\n",
    "    \n",
    "    axis.plot(X3[:,0], X3[:,1], 'o', color='yellow', markersize=1, alpha=alpha)\n",
    "    \n",
    "    axis.plot(X4[:,0], X4[:,1], 'o', color='brown', markersize=1, alpha=alpha)\n",
    "    \n",
    "    axis.plot(X5[:,0], X5[:,1], 'o', color='black', markersize=1, alpha=alpha)\n",
    "    \n",
    "    axis.plot(X6[:,0], X6[:,1], 'o', color='pink', markersize=1, alpha=alpha)\n",
    "    \n",
    "    axis.plot(X7[:,0], X7[:,1], 'o', color='orange', markersize=1, alpha=alpha)\n",
    "    \n",
    "    axis.plot(X8[:,0], X8[:,1], 'o', color='cyan', markersize=1, alpha=alpha)\n",
    "    \n",
    "    axis.plot(X9[:,0], X9[:,1], 'o', color='gray', markersize=1, alpha=alpha)\n",
    "    \n",
    "    # set axes limits\n",
    "    axis.set_xlim(3.5,8)\n",
    "    axis.set_ylim(0,6)\n",
    "    axis.set_aspect('equal')\n",
    "    \n",
    "    axis.set_xlabel('x')\n",
    "    axis.set_ylabel('y')\n",
    "\n",
    "figure,axis = pyplot.subplots(1,1)\n",
    "plot_data(ans[0],test_ys,axis)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(weights['w1'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python optimisation variables\n",
    "import tensorflow as tf\n",
    "learning_rate = 0.01\n",
    "epochs = 30\n",
    "batch_size = 100\n",
    "\n",
    "# declare the training data placeholders\n",
    "# input x - for 28 x 28 pixels = 784\n",
    "x = tf.placeholder(tf.float32, [None, 10])\n",
    "# now declare the output data placeholder - 10 digits\n",
    "y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now declare the weights connecting the input to the hidden layer\n",
    "W1 = tf.Variable(tf.random_normal([10, 300], stddev=0.03), name='W1')\n",
    "b1 = tf.Variable(tf.random_normal([300]), name='b1')\n",
    "# and the weights connecting the hidden layer to the output layer\n",
    "W2 = tf.Variable(tf.random_normal([300, 10], stddev=0.03), name='W2')\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='b2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the output of the hidden layer\n",
    "hidden_out = tf.add(tf.matmul(x, W1), b1)\n",
    "hidden_out = tf.nn.relu(hidden_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = tf.nn.softmax(tf.add(tf.matmul(hidden_out, W2), b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_clipped = tf.clip_by_value(y_, 1e-10, 0.9999999)\n",
    "cross_entropy = -tf.reduce_mean(tf.reduce_sum(y * tf.log(y_clipped)\n",
    "                         + (1 - y) * tf.log(1 - y_clipped), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an optimiser\n",
    "optimiser = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally setup the initialisation operator\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# define an accuracy assessment operation\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost = 3.243\n",
      "Epoch: 2 cost = 3.197\n",
      "Epoch: 3 cost = 3.121\n",
      "Epoch: 4 cost = 3.003\n",
      "Epoch: 5 cost = 2.871\n",
      "Epoch: 6 cost = 2.762\n",
      "Epoch: 7 cost = 2.683\n",
      "Epoch: 8 cost = 2.623\n",
      "Epoch: 9 cost = 2.591\n",
      "Epoch: 10 cost = 2.535\n",
      "Epoch: 11 cost = 2.518\n",
      "Epoch: 12 cost = 2.484\n",
      "Epoch: 13 cost = 2.463\n",
      "Epoch: 14 cost = 2.430\n",
      "Epoch: 15 cost = 2.416\n",
      "Epoch: 16 cost = 2.388\n",
      "Epoch: 17 cost = 2.380\n",
      "Epoch: 18 cost = 2.353\n",
      "Epoch: 19 cost = 2.340\n",
      "Epoch: 20 cost = 2.325\n",
      "Epoch: 21 cost = 2.310\n",
      "Epoch: 22 cost = 2.286\n",
      "Epoch: 23 cost = 2.277\n",
      "Epoch: 24 cost = 2.265\n",
      "Epoch: 25 cost = 2.246\n",
      "Epoch: 26 cost = 2.239\n",
      "Epoch: 27 cost = 2.225\n",
      "Epoch: 28 cost = 2.204\n",
      "Epoch: 29 cost = 2.207\n",
      "Epoch: 30 cost = 2.182\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # Launch the graph\n",
    "#sess = tf.Session()\n",
    "\n",
    "    # op to write logs to Tensorboard\n",
    "#summary_writer = tf.train.SummaryWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "    # Training cycle\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    for epoch in range(30):\n",
    "        avg_cost=0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            left_batch_xs, left_batch_ys = mnist.train.next_batch(batch_size)\n",
    "            ans = sess.run([pred_left], feed_dict = { x_left: left_batch_xs})\n",
    "            ans=ans[0]\n",
    "            left_batch_ys=np_utils.to_categorical(left_batch_ys)\n",
    "        #right_batch_xs, right_batch_ys = mnist.train.next_batch(batch_size)\n",
    "        #labels = np.zeros((batch_size, 1))\n",
    "            _, c = sess.run([optimiser, cross_entropy], feed_dict={x: ans, y: left_batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "        print(\"Epoch:\", (epoch + 1), \"cost =\", \"{:.3f}\".format(avg_cost)) \n",
    "    test_xs, test_ys = mnist.train.next_batch(5000)\n",
    "    #test_ys=np_utils.to_categorical(test_ys)\n",
    "    #print(sess.run(accuracy, feed_dict={x_left: test_xs, y: test_ys}))\n",
    "    #test_xs, test_ys = mnist.train.next_batch(5000)\n",
    "    #ans = sess.run([pred_left], feed_dict = { x_left: test_xs})\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 ... 1 5 5]\n"
     ]
    }
   ],
   "source": [
    "print(test_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'W1_1:0' shape=(784, 256) dtype=float32_ref>\n",
      "<tf.Variable 'W1_2:0' shape=(2, 300) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "print(weights['w1'])\n",
    "print(W1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
