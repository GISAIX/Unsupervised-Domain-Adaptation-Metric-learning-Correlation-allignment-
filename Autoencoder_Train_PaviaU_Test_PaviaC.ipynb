{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniruddha/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import numpy\n",
    "import PIL\n",
    "from PIL import Image\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from math import sqrt\n",
    "\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1096, 715, 102)\n",
      "(1096, 715)\n",
      "(72933, 102)\n",
      "(72933,)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('/home/aniruddha/deep-learning-projects/Siamese_Networks/Dataset/PaviaCentre.mat')\n",
    "arr = mat['pavia']\n",
    "arr = np.array(arr)\n",
    "print(arr.shape)\n",
    "\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat('/home/aniruddha/deep-learning-projects/Siamese_Networks/Dataset/PaviaCentre_gt.mat')\n",
    "arr1 = mat['pavia_gt']\n",
    "arr1 = np.array(arr1)\n",
    "print(arr1.shape)\n",
    "\n",
    "a=[]\n",
    "label=[]\n",
    "k=0\n",
    "for i in range(0,arr1.shape[0]):\n",
    "    for j in range(0,arr1[i].shape[0]):\n",
    "        a.append(arr[i][j])\n",
    "        label.append(arr1[i][j])\n",
    "        \n",
    "a=np.array(a)\n",
    "label=np.array(label)\n",
    "\n",
    "X_train=[]\n",
    "y_train=[]\n",
    "for i in range (0,a.shape[0]):\n",
    "    if(label[i]==2):\n",
    "        y_train.append(0)\n",
    "    if(label[i]==3):\n",
    "        y_train.append(1)\n",
    "    if(label[i]==4):\n",
    "        y_train.append(2)\n",
    "    if(label[i]==5):\n",
    "        y_train.append(3)\n",
    "    if(label[i]==7):\n",
    "        y_train.append(4)\n",
    "    if(label[i]==8):\n",
    "        y_train.append(5)\n",
    "    if(label[i]==9):\n",
    "        y_train.append(6)\n",
    "    if (label[i]==2 or label[i]==3 or label[i]==4 or label[i]==5 or label[i]==7 or label[i]==8 or label[i]==9):\n",
    "        X_train.append(a[i])\n",
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniruddha/anaconda3/envs/tensorflow/lib/python3.5/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint16 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72933, 64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state = 0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=64)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(610, 340)\n",
      "(207400, 103)\n",
      "(207400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniruddha/anaconda3/envs/tensorflow/lib/python3.5/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint16 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39332, 64)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('/home/aniruddha/deep-learning-projects/Siamese_Networks/Dataset/PaviaU.mat')\n",
    "arr = mat['paviaU']\n",
    "arr = np.array(arr)\n",
    "\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat('/home/aniruddha/deep-learning-projects/Siamese_Networks/Dataset/PaviaU_gt.mat')\n",
    "arr1 = mat['paviaU_gt']\n",
    "arr1 = np.array(arr1)\n",
    "print(arr1.shape)\n",
    "\n",
    "a=[]\n",
    "label=[]\n",
    "k=0\n",
    "for i in range(0,arr1.shape[0]):\n",
    "    for j in range(0,arr1[i].shape[0]):\n",
    "        a.append(arr[i][j])\n",
    "        label.append(arr1[i][j])\n",
    "        \n",
    "a=np.array(a)\n",
    "label=np.array(label)\n",
    "print(a.shape)\n",
    "print(label.shape)\n",
    "\n",
    "X_train1=[]\n",
    "y_train1=[]\n",
    "for i in range (0,a.shape[0]):\n",
    "    if(label[i]==4):\n",
    "        y_train1.append(0)\n",
    "    if(label[i]==1):\n",
    "        y_train1.append(1)\n",
    "    if(label[i]==8):\n",
    "        y_train1.append(2)\n",
    "    if(label[i]==7):\n",
    "        y_train1.append(3)\n",
    "    if(label[i]==9):\n",
    "        y_train1.append(4)\n",
    "    if(label[i]==2):\n",
    "        y_train1.append(5)\n",
    "    if(label[i]==6):\n",
    "        y_train1.append(6)\n",
    "    if (label[i]==4 or label[i]==1 or label[i]==8 or label[i]==7 or label[i]==9 or label[i]==2 or label[i]==6):\n",
    "        X_train1.append(a[i])\n",
    "X_train1=np.array(X_train1)\n",
    "y_train1=np.array(y_train1)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X_train1, y_train1 = shuffle(X_train1, y_train1, random_state = 0)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train1 = StandardScaler().fit_transform(X_train1)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=64)\n",
    "X_train1 = pca.fit_transform(X_train1)\n",
    "print(X_train1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.423585702771796\n",
      "104.56701566525479\n"
     ]
    }
   ],
   "source": [
    "print(X_train.max())\n",
    "print(X_train1.max())\n",
    "X_train=X_train.astype('float32')\n",
    "X_train1=X_train1.astype('float32')\n",
    "X_train=X_train/100\n",
    "X_train1=X_train1/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 64)\n",
      "(39332, 64)\n",
      "(22933, 64)\n"
     ]
    }
   ],
   "source": [
    "X_test=X_train[50000:72933,:]\n",
    "y_test=y_train[50000:72933]\n",
    "X_train=X_train[0:50000,:]\n",
    "y_train=y_train[0:50000]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train1.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_steps = 20\n",
    "batch_size = 20\n",
    "total_numbers = 291\n",
    "display_step = 1000\n",
    "examples_to_show = 10\n",
    "\n",
    "# Network Parameters\n",
    "num_hidden_1 = 32 # 1st layer num features\n",
    "num_hidden_2 = 16 # 2nd layer num features (the latent dim)\n",
    "num_input = 64 \n",
    "num_classes = 7\n",
    "\n",
    "# tf Graph input (only pictures)\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(tf.random_uniform([num_input, num_hidden_1], minval=-4*np.sqrt(6.0/(num_input + num_hidden_1)), maxval=4*np.sqrt(6.0/(num_input + num_hidden_1)))),\n",
    "    'encoder_h2': tf.Variable(tf.random_uniform([num_hidden_1, num_hidden_2], minval=-4*np.sqrt(6.0/(num_hidden_1 + num_hidden_2)), maxval=4*np.sqrt(6.0/(num_hidden_1 + num_hidden_2)))),\n",
    "    'decoder_h1': tf.Variable(tf.random_uniform([num_hidden_2, num_hidden_1], minval=-4*np.sqrt(6.0/(num_hidden_1 + num_hidden_2)), maxval=4*np.sqrt(6.0/(num_hidden_1 + num_hidden_2)))),\n",
    "    'decoder_h2': tf.Variable(tf.random_uniform([num_hidden_1, num_input], minval=-4*np.sqrt(6.0/(num_input + num_hidden_1)), maxval=4*np.sqrt(6.0/(num_input + num_hidden_1)))),\n",
    "    'classifier1_h': tf.Variable(tf.random_uniform([num_hidden_2, 10], minval=-4*np.sqrt(6.0/(10 + num_hidden_2)), maxval=4*np.sqrt(6.0/(10 + num_hidden_2)))),\n",
    "    'classifier_h': tf.Variable(tf.random_uniform([10, num_classes], minval=-4*np.sqrt(6.0/(10 + num_classes)), maxval=4*np.sqrt(6.0/(10 + num_classes)))),\n",
    "}\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(tf.truncated_normal([num_hidden_1])/sqrt(num_hidden_1)),\n",
    "    'encoder_b2': tf.Variable(tf.truncated_normal([num_hidden_2])/sqrt(num_hidden_2)),\n",
    "    'decoder_b1': tf.Variable(tf.truncated_normal([num_hidden_1])/sqrt(num_hidden_1)),\n",
    "    'decoder_b2': tf.Variable(tf.truncated_normal([num_input])/sqrt(num_hidden_2)),\n",
    "    'classifier1_b': tf.Variable(tf.truncated_normal([10])/sqrt(10)),\n",
    "    'classifier_b': tf.Variable(tf.truncated_normal([num_classes])/sqrt(num_classes)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the encoder\n",
    "def encoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']),\n",
    "                                   biases['encoder_b1']))\n",
    "    # Encoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']),\n",
    "                                   biases['encoder_b2']))\n",
    "    return layer_2\n",
    "\n",
    "\n",
    "# Building the decoder\n",
    "def decoder(x):\n",
    "    # Decoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']),\n",
    "                                   biases['decoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']),\n",
    "                                   biases['decoder_b2']))\n",
    "    return layer_2\n",
    "\n",
    "# Construct model\n",
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)\n",
    "\n",
    "# Prediction\n",
    "y_pred = decoder_op\n",
    "classify1 = tf.nn.sigmoid(tf.add(tf.matmul(encoder_op, weights['classifier1_h']), biases['classifier1_b']))\n",
    "label_pred = tf.nn.softmax(tf.add(tf.matmul(classify1, weights['classifier_h']), biases['classifier_b']))\n",
    "y_clipped = tf.clip_by_value(label_pred, 1e-10, 0.9999999)\n",
    "\n",
    "\n",
    "# Targets (Labels) are the input data.\n",
    "y_true = X\n",
    "label_true = Y\n",
    "\n",
    "# Define loss and optimizer, minimize the squared error\n",
    "loss_autoencoder = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
    "cross_entropy_loss = -tf.reduce_mean(tf.reduce_sum(label_true * tf.log(y_clipped)\n",
    "                         + (1 - label_true) * tf.log(1 - y_clipped), axis=1))\n",
    "loss_total = loss_autoencoder+cross_entropy_loss\n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss_total)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39332, 7)\n",
      "(22933, 7)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "y_test11 = np_utils.to_categorical(y_test)\n",
    "y_train11 = np_utils.to_categorical(y_train1)\n",
    "print(y_train11.shape)\n",
    "print(y_test11.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an accuracy assessment operation\n",
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(label_pred, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost = 0.02628749\n",
      "Epoch: 1 accuracy = 0.12786026\n",
      "Epoch: 2 cost = 0.02511806\n",
      "Epoch: 2 accuracy = 0.12786026\n",
      "Epoch: 3 cost = 0.02400085\n",
      "Epoch: 3 accuracy = 0.12786026\n",
      "Epoch: 4 cost = 0.02292105\n",
      "Epoch: 4 accuracy = 0.12786026\n",
      "Epoch: 5 cost = 0.02187795\n",
      "Epoch: 5 accuracy = 0.12786026\n",
      "Epoch: 6 cost = 0.02087924\n",
      "Epoch: 6 accuracy = 0.12786026\n",
      "Epoch: 7 cost = 0.01993689\n",
      "Epoch: 7 accuracy = 0.12786026\n",
      "Epoch: 8 cost = 0.01906220\n",
      "Epoch: 8 accuracy = 0.12786026\n",
      "Epoch: 9 cost = 0.01826031\n",
      "Epoch: 9 accuracy = 0.12786028\n",
      "Epoch: 10 cost = 0.01752586\n",
      "Epoch: 10 accuracy = 0.12786026\n",
      "Epoch: 11 cost = 0.01684174\n",
      "Epoch: 11 accuracy = 0.12786026\n",
      "Epoch: 12 cost = 0.01618174\n",
      "Epoch: 12 accuracy = 0.12786026\n",
      "Epoch: 13 cost = 0.01551575\n",
      "Epoch: 13 accuracy = 0.12786026\n",
      "Epoch: 14 cost = 0.01481585\n",
      "Epoch: 14 accuracy = 0.12786026\n",
      "Epoch: 15 cost = 0.01406221\n",
      "Epoch: 15 accuracy = 0.12786026\n",
      "Epoch: 16 cost = 0.01324943\n",
      "Epoch: 16 accuracy = 0.12786026\n",
      "Epoch: 17 cost = 0.01239465\n",
      "Epoch: 17 accuracy = 0.12786026\n",
      "Epoch: 18 cost = 0.01154484\n",
      "Epoch: 18 accuracy = 0.12786026\n",
      "Epoch: 19 cost = 0.01077082\n",
      "Epoch: 19 accuracy = 0.12786026\n",
      "Epoch: 20 cost = 0.01013623\n",
      "Epoch: 20 accuracy = 0.12786026\n",
      "Epoch: 21 cost = 0.00966313\n",
      "Epoch: 21 accuracy = 0.47414342\n",
      "Epoch: 22 cost = 0.00933161\n",
      "Epoch: 22 accuracy = 0.47414345\n",
      "Epoch: 23 cost = 0.00910522\n",
      "Epoch: 23 accuracy = 0.47414345\n",
      "Epoch: 24 cost = 0.00895033\n",
      "Epoch: 24 accuracy = 0.47414345\n",
      "Epoch: 25 cost = 0.00884193\n",
      "Epoch: 25 accuracy = 0.47414345\n",
      "Epoch: 26 cost = 0.00876288\n",
      "Epoch: 26 accuracy = 0.47414345\n",
      "Epoch: 27 cost = 0.00870202\n",
      "Epoch: 27 accuracy = 0.47414345\n",
      "Epoch: 28 cost = 0.00865248\n",
      "Epoch: 28 accuracy = 0.47414345\n",
      "Epoch: 29 cost = 0.00861034\n",
      "Epoch: 29 accuracy = 0.47414345\n",
      "Epoch: 30 cost = 0.00857348\n",
      "Epoch: 30 accuracy = 0.47414342\n",
      "Epoch: 31 cost = 0.00854073\n",
      "Epoch: 31 accuracy = 0.47414345\n",
      "Epoch: 32 cost = 0.00851130\n",
      "Epoch: 32 accuracy = 0.47414345\n",
      "Epoch: 33 cost = 0.00848448\n",
      "Epoch: 33 accuracy = 0.47414345\n",
      "Epoch: 34 cost = 0.00845956\n",
      "Epoch: 34 accuracy = 0.47414345\n",
      "Epoch: 35 cost = 0.00843581\n",
      "Epoch: 35 accuracy = 0.47414345\n",
      "Epoch: 36 cost = 0.00841258\n",
      "Epoch: 36 accuracy = 0.47414345\n",
      "Epoch: 37 cost = 0.00838931\n",
      "Epoch: 37 accuracy = 0.47414342\n",
      "Epoch: 38 cost = 0.00836553\n",
      "Epoch: 38 accuracy = 0.47414345\n",
      "Epoch: 39 cost = 0.00834087\n",
      "Epoch: 39 accuracy = 0.47414345\n",
      "Epoch: 40 cost = 0.00831499\n",
      "Epoch: 40 accuracy = 0.47414345\n",
      "Epoch: 41 cost = 0.00828764\n",
      "Epoch: 41 accuracy = 0.47414345\n",
      "Epoch: 42 cost = 0.00825855\n",
      "Epoch: 42 accuracy = 0.47414345\n",
      "Epoch: 43 cost = 0.00822753\n",
      "Epoch: 43 accuracy = 0.47414342\n",
      "Epoch: 44 cost = 0.00819444\n",
      "Epoch: 44 accuracy = 0.47414348\n",
      "Epoch: 45 cost = 0.00815924\n",
      "Epoch: 45 accuracy = 0.47414345\n",
      "Epoch: 46 cost = 0.00812201\n",
      "Epoch: 46 accuracy = 0.47414345\n",
      "Epoch: 47 cost = 0.00808301\n",
      "Epoch: 47 accuracy = 0.47414342\n",
      "Epoch: 48 cost = 0.00804266\n",
      "Epoch: 48 accuracy = 0.47414345\n",
      "Epoch: 49 cost = 0.00800155\n",
      "Epoch: 49 accuracy = 0.47414348\n",
      "Epoch: 50 cost = 0.00796043\n",
      "Epoch: 50 accuracy = 0.47414345\n",
      "Epoch: 51 cost = 0.00792010\n",
      "Epoch: 51 accuracy = 0.47414348\n",
      "Epoch: 52 cost = 0.00788130\n",
      "Epoch: 52 accuracy = 0.47414345\n",
      "Epoch: 53 cost = 0.00784464\n",
      "Epoch: 53 accuracy = 0.47414342\n",
      "Epoch: 54 cost = 0.00781049\n",
      "Epoch: 54 accuracy = 0.47414345\n",
      "Epoch: 55 cost = 0.00777898\n",
      "Epoch: 55 accuracy = 0.47414345\n",
      "Epoch: 56 cost = 0.00774999\n",
      "Epoch: 56 accuracy = 0.47414345\n",
      "Epoch: 57 cost = 0.00772334\n",
      "Epoch: 57 accuracy = 0.47414345\n",
      "Epoch: 58 cost = 0.00769915\n",
      "Epoch: 58 accuracy = 0.47414345\n",
      "Epoch: 59 cost = 0.00767811\n",
      "Epoch: 59 accuracy = 0.47414348\n",
      "Epoch: 60 cost = 0.00766080\n",
      "Epoch: 60 accuracy = 0.47414345\n",
      "Epoch: 61 cost = 0.00764696\n",
      "Epoch: 61 accuracy = 0.47414345\n",
      "Epoch: 62 cost = 0.00763585\n",
      "Epoch: 62 accuracy = 0.47414345\n",
      "Epoch: 63 cost = 0.00762675\n",
      "Epoch: 63 accuracy = 0.47414345\n",
      "Epoch: 64 cost = 0.00761913\n",
      "Epoch: 64 accuracy = 0.47414345\n",
      "Epoch: 65 cost = 0.00761264\n",
      "Epoch: 65 accuracy = 0.47414345\n",
      "Epoch: 66 cost = 0.00760703\n",
      "Epoch: 66 accuracy = 0.47414345\n",
      "Epoch: 67 cost = 0.00760212\n",
      "Epoch: 67 accuracy = 0.47414345\n",
      "Epoch: 68 cost = 0.00759776\n",
      "Epoch: 68 accuracy = 0.47414345\n",
      "Epoch: 69 cost = 0.00759382\n",
      "Epoch: 69 accuracy = 0.47414342\n",
      "Epoch: 70 cost = 0.00759022\n",
      "Epoch: 70 accuracy = 0.47414345\n",
      "Epoch: 71 cost = 0.00758686\n",
      "Epoch: 71 accuracy = 0.47414345\n",
      "Epoch: 72 cost = 0.00758368\n",
      "Epoch: 72 accuracy = 0.47414345\n",
      "Epoch: 73 cost = 0.00758060\n",
      "Epoch: 73 accuracy = 0.47414345\n",
      "Epoch: 74 cost = 0.00757757\n",
      "Epoch: 74 accuracy = 0.47414342\n",
      "Epoch: 75 cost = 0.00757451\n",
      "Epoch: 75 accuracy = 0.47414345\n",
      "Epoch: 76 cost = 0.00757132\n",
      "Epoch: 76 accuracy = 0.47414345\n",
      "Epoch: 77 cost = 0.00756787\n",
      "Epoch: 77 accuracy = 0.47414345\n",
      "Epoch: 78 cost = 0.00756407\n",
      "Epoch: 78 accuracy = 0.47414345\n",
      "Epoch: 79 cost = 0.00755986\n",
      "Epoch: 79 accuracy = 0.47414342\n",
      "Epoch: 80 cost = 0.00755514\n",
      "Epoch: 80 accuracy = 0.47414345\n",
      "Epoch: 81 cost = 0.00754971\n",
      "Epoch: 81 accuracy = 0.47414345\n",
      "Epoch: 82 cost = 0.00754339\n",
      "Epoch: 82 accuracy = 0.47414345\n",
      "Epoch: 83 cost = 0.00753624\n",
      "Epoch: 83 accuracy = 0.47414345\n",
      "Epoch: 84 cost = 0.00753011\n",
      "Epoch: 84 accuracy = 0.47414345\n",
      "Epoch: 85 cost = 0.00752518\n",
      "Epoch: 85 accuracy = 0.47414345\n",
      "Epoch: 86 cost = 0.00750919\n",
      "Epoch: 86 accuracy = 0.47414342\n",
      "Epoch: 87 cost = 0.00749085\n",
      "Epoch: 87 accuracy = 0.47414342\n",
      "Epoch: 88 cost = 0.00747490\n",
      "Epoch: 88 accuracy = 0.47414345\n",
      "Epoch: 89 cost = 0.00746183\n",
      "Epoch: 89 accuracy = 0.47414345\n",
      "Epoch: 90 cost = 0.00746702\n",
      "Epoch: 90 accuracy = 0.47414345\n",
      "Epoch: 91 cost = 0.00744605\n",
      "Epoch: 91 accuracy = 0.47416884\n",
      "Epoch: 92 cost = 0.00739827\n",
      "Epoch: 92 accuracy = 0.47416890\n",
      "Epoch: 93 cost = 0.00738514\n",
      "Epoch: 93 accuracy = 0.47416890\n",
      "Epoch: 94 cost = 0.00737236\n",
      "Epoch: 94 accuracy = 0.47416887\n",
      "Epoch: 95 cost = 0.00734530\n",
      "Epoch: 95 accuracy = 0.47416890\n",
      "Epoch: 96 cost = 0.00731293\n",
      "Epoch: 96 accuracy = 0.47416890\n",
      "Epoch: 97 cost = 0.00728449\n",
      "Epoch: 97 accuracy = 0.47416887\n",
      "Epoch: 98 cost = 0.00725678\n",
      "Epoch: 98 accuracy = 0.47416890\n",
      "Epoch: 99 cost = 0.00722766\n",
      "Epoch: 99 accuracy = 0.47416884\n",
      "Epoch: 100 cost = 0.00719752\n",
      "Epoch: 100 accuracy = 0.47419429\n",
      "Epoch: 101 cost = 0.00716594\n",
      "Epoch: 101 accuracy = 0.47434682\n",
      "Epoch: 102 cost = 0.00713287\n",
      "Epoch: 102 accuracy = 0.47449940\n",
      "Epoch: 103 cost = 0.00709895\n",
      "Epoch: 103 accuracy = 0.47467735\n",
      "Epoch: 104 cost = 0.00706461\n",
      "Epoch: 104 accuracy = 0.47490618\n",
      "Epoch: 105 cost = 0.00703013\n",
      "Epoch: 105 accuracy = 0.47508416\n",
      "Epoch: 106 cost = 0.00699613\n",
      "Epoch: 106 accuracy = 0.47521126\n",
      "Epoch: 107 cost = 0.00696356\n",
      "Epoch: 107 accuracy = 0.47521126\n",
      "Epoch: 108 cost = 0.00693544\n",
      "Epoch: 108 accuracy = 0.47521126\n",
      "Epoch: 109 cost = 0.00690748\n",
      "Epoch: 109 accuracy = 0.47541469\n",
      "Epoch: 110 cost = 0.00685705\n",
      "Epoch: 110 accuracy = 0.47584686\n",
      "Epoch: 111 cost = 0.00680268\n",
      "Epoch: 111 accuracy = 0.47721979\n",
      "Epoch: 112 cost = 0.00675967\n",
      "Epoch: 112 accuracy = 0.48535568\n",
      "Epoch: 113 cost = 0.00671458\n",
      "Epoch: 113 accuracy = 0.50350887\n",
      "Epoch: 114 cost = 0.00670007\n",
      "Epoch: 114 accuracy = 0.57909632\n",
      "Epoch: 115 cost = 0.00671176\n",
      "Epoch: 115 accuracy = 0.56905359\n",
      "Epoch: 116 cost = 0.00662642\n",
      "Epoch: 116 accuracy = 0.53734905\n",
      "Epoch: 117 cost = 0.00655759\n",
      "Epoch: 117 accuracy = 0.52334011\n",
      "Epoch: 118 cost = 0.00650779\n",
      "Epoch: 118 accuracy = 0.51334822\n",
      "Epoch: 119 cost = 0.00646569\n",
      "Epoch: 119 accuracy = 0.50328010\n",
      "Epoch: 120 cost = 0.00643122\n",
      "Epoch: 120 accuracy = 0.48894057\n",
      "Epoch: 121 cost = 0.00648404\n",
      "Epoch: 121 accuracy = 0.47579601\n",
      "Epoch: 122 cost = 0.00659362\n",
      "Epoch: 122 accuracy = 0.48108438\n",
      "Epoch: 123 cost = 0.00638181\n",
      "Epoch: 123 accuracy = 0.49247465\n",
      "Epoch: 124 cost = 0.00627369\n",
      "Epoch: 124 accuracy = 0.49926299\n",
      "Epoch: 125 cost = 0.00621859\n",
      "Epoch: 125 accuracy = 0.50617844\n",
      "Epoch: 126 cost = 0.00617408\n",
      "Epoch: 126 accuracy = 0.52839965\n",
      "Epoch: 127 cost = 0.00613751\n",
      "Epoch: 127 accuracy = 0.61128390\n",
      "Epoch: 128 cost = 0.00617586\n",
      "Epoch: 128 accuracy = 0.63810682\n",
      "Epoch: 129 cost = 0.00627845\n",
      "Epoch: 129 accuracy = 0.63302195\n",
      "Epoch: 130 cost = 0.00607206\n",
      "Epoch: 130 accuracy = 0.62442839\n",
      "Epoch: 131 cost = 0.00598623\n",
      "Epoch: 131 accuracy = 0.61667395\n",
      "Epoch: 132 cost = 0.00593587\n",
      "Epoch: 132 accuracy = 0.61446202\n",
      "Epoch: 133 cost = 0.00589480\n",
      "Epoch: 133 accuracy = 0.61708063\n",
      "Epoch: 134 cost = 0.00585742\n",
      "Epoch: 134 accuracy = 0.63004726\n",
      "Epoch: 135 cost = 0.00583287\n",
      "Epoch: 135 accuracy = 0.64670044\n",
      "Epoch: 136 cost = 0.00587947\n",
      "Epoch: 136 accuracy = 0.64108157\n",
      "Epoch: 137 cost = 0.00591466\n",
      "Epoch: 137 accuracy = 0.65295482\n",
      "Epoch: 138 cost = 0.00574497\n",
      "Epoch: 138 accuracy = 0.65191245\n",
      "Epoch: 139 cost = 0.00564736\n",
      "Epoch: 139 accuracy = 0.64921743\n",
      "Epoch: 140 cost = 0.00559440\n",
      "Epoch: 140 accuracy = 0.64209849\n",
      "Epoch: 141 cost = 0.00555901\n",
      "Epoch: 141 accuracy = 0.61593658\n",
      "Epoch: 142 cost = 0.00555456\n",
      "Epoch: 142 accuracy = 0.51108545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143 cost = 0.00568222\n",
      "Epoch: 143 accuracy = 0.49445772\n",
      "Epoch: 144 cost = 0.00565369\n",
      "Epoch: 144 accuracy = 0.55761254\n",
      "Epoch: 145 cost = 0.00544943\n",
      "Epoch: 145 accuracy = 0.62262321\n",
      "Epoch: 146 cost = 0.00536575\n",
      "Epoch: 146 accuracy = 0.63884425\n",
      "Epoch: 147 cost = 0.00531886\n",
      "Epoch: 147 accuracy = 0.64563262\n",
      "Epoch: 148 cost = 0.00528118\n",
      "Epoch: 148 accuracy = 0.64860731\n",
      "Epoch: 149 cost = 0.00524615\n",
      "Epoch: 149 accuracy = 0.65112424\n",
      "Epoch: 150 cost = 0.00521191\n",
      "Epoch: 150 accuracy = 0.65397185\n",
      "Epoch: 151 cost = 0.00518321\n",
      "Epoch: 151 accuracy = 0.66020089\n",
      "Epoch: 152 cost = 0.00527054\n",
      "Epoch: 152 accuracy = 0.66210771\n",
      "Epoch: 153 cost = 0.00548931\n",
      "Epoch: 153 accuracy = 0.66233659\n",
      "Epoch: 154 cost = 0.00513675\n",
      "Epoch: 154 accuracy = 0.66226023\n",
      "Epoch: 155 cost = 0.00504772\n",
      "Epoch: 155 accuracy = 0.66259080\n",
      "Epoch: 156 cost = 0.00501771\n",
      "Epoch: 156 accuracy = 0.66396374\n",
      "Epoch: 157 cost = 0.00499898\n",
      "Epoch: 157 accuracy = 0.66970968\n",
      "Epoch: 158 cost = 0.00499091\n",
      "Epoch: 158 accuracy = 0.69732088\n",
      "Epoch: 159 cost = 0.00504221\n",
      "Epoch: 159 accuracy = 0.65643805\n",
      "Epoch: 160 cost = 0.00513955\n",
      "Epoch: 160 accuracy = 0.68562555\n",
      "Epoch: 161 cost = 0.00501973\n",
      "Epoch: 161 accuracy = 0.71450788\n",
      "Epoch: 162 cost = 0.00489563\n",
      "Epoch: 162 accuracy = 0.70606685\n",
      "Epoch: 163 cost = 0.00484634\n",
      "Epoch: 163 accuracy = 0.69841415\n",
      "Epoch: 164 cost = 0.00481905\n",
      "Epoch: 164 accuracy = 0.68961728\n",
      "Epoch: 165 cost = 0.00479831\n",
      "Epoch: 165 accuracy = 0.68038797\n",
      "Epoch: 166 cost = 0.00478258\n",
      "Epoch: 166 accuracy = 0.66932839\n",
      "Epoch: 167 cost = 0.00480171\n",
      "Epoch: 167 accuracy = 0.66452312\n",
      "Epoch: 168 cost = 0.00491964\n",
      "Epoch: 168 accuracy = 0.66625196\n",
      "Epoch: 169 cost = 0.00483291\n",
      "Epoch: 169 accuracy = 0.67789638\n",
      "Epoch: 170 cost = 0.00470132\n",
      "Epoch: 170 accuracy = 0.68946457\n",
      "Epoch: 171 cost = 0.00465931\n",
      "Epoch: 171 accuracy = 0.70103282\n",
      "Epoch: 172 cost = 0.00465525\n",
      "Epoch: 172 accuracy = 0.71712667\n",
      "Epoch: 173 cost = 0.00468368\n",
      "Epoch: 173 accuracy = 0.72437263\n",
      "Epoch: 174 cost = 0.00475595\n",
      "Epoch: 174 accuracy = 0.71781313\n",
      "Epoch: 175 cost = 0.00472977\n",
      "Epoch: 175 accuracy = 0.72976267\n",
      "Epoch: 176 cost = 0.00462340\n",
      "Epoch: 176 accuracy = 0.73179662\n",
      "Epoch: 177 cost = 0.00456907\n",
      "Epoch: 177 accuracy = 0.72816092\n",
      "Epoch: 178 cost = 0.00454416\n",
      "Epoch: 178 accuracy = 0.72406751\n",
      "Epoch: 179 cost = 0.00452882\n",
      "Epoch: 179 accuracy = 0.72060978\n",
      "Epoch: 180 cost = 0.00451323\n",
      "Epoch: 180 accuracy = 0.72040635\n",
      "Epoch: 181 cost = 0.00449463\n",
      "Epoch: 181 accuracy = 0.72366077\n",
      "Epoch: 182 cost = 0.00447852\n",
      "Epoch: 182 accuracy = 0.73024571\n",
      "Epoch: 183 cost = 0.00448738\n",
      "Epoch: 183 accuracy = 0.72648287\n",
      "Epoch: 184 cost = 0.00458451\n",
      "Epoch: 184 accuracy = 0.71387219\n",
      "Epoch: 185 cost = 0.00454600\n",
      "Epoch: 185 accuracy = 0.73596627\n",
      "Epoch: 186 cost = 0.00440359\n",
      "Epoch: 186 accuracy = 0.73126280\n",
      "Epoch: 187 cost = 0.00436855\n",
      "Epoch: 187 accuracy = 0.71514350\n",
      "Epoch: 188 cost = 0.00437531\n",
      "Epoch: 188 accuracy = 0.69854122\n",
      "Epoch: 189 cost = 0.00437236\n",
      "Epoch: 189 accuracy = 0.69498181\n",
      "Epoch: 190 cost = 0.00435337\n",
      "Epoch: 190 accuracy = 0.69706661\n",
      "Epoch: 191 cost = 0.00433080\n",
      "Epoch: 191 accuracy = 0.70105827\n",
      "Epoch: 192 cost = 0.00430342\n",
      "Epoch: 192 accuracy = 0.70660084\n",
      "Epoch: 193 cost = 0.00427603\n",
      "Epoch: 193 accuracy = 0.71445704\n",
      "Epoch: 194 cost = 0.00425785\n",
      "Epoch: 194 accuracy = 0.72714400\n",
      "Epoch: 195 cost = 0.00430683\n",
      "Epoch: 195 accuracy = 0.72716933\n",
      "Epoch: 196 cost = 0.00446377\n",
      "Epoch: 196 accuracy = 0.72971177\n",
      "Epoch: 197 cost = 0.00433665\n",
      "Epoch: 197 accuracy = 0.74049181\n",
      "Epoch: 198 cost = 0.00421116\n",
      "Epoch: 198 accuracy = 0.73759347\n",
      "Epoch: 199 cost = 0.00418383\n",
      "Epoch: 199 accuracy = 0.73428828\n",
      "Epoch: 200 cost = 0.00417565\n",
      "Epoch: 200 accuracy = 0.73121190\n",
      "Epoch: 201 cost = 0.00416970\n",
      "Epoch: 201 accuracy = 0.72854233\n",
      "Epoch: 202 cost = 0.00415849\n",
      "Epoch: 202 accuracy = 0.72734737\n",
      "Epoch: 203 cost = 0.00414296\n",
      "Epoch: 203 accuracy = 0.72727108\n",
      "Epoch: 204 cost = 0.00412681\n",
      "Epoch: 204 accuracy = 0.72811002\n",
      "Epoch: 205 cost = 0.00411154\n",
      "Epoch: 205 accuracy = 0.73123717\n",
      "Epoch: 206 cost = 0.00410045\n",
      "Epoch: 206 accuracy = 0.73840702\n",
      "Epoch: 207 cost = 0.00414723\n",
      "Epoch: 207 accuracy = 0.73329675\n",
      "Epoch: 208 cost = 0.00430481\n",
      "Epoch: 208 accuracy = 0.73952568\n",
      "Epoch: 209 cost = 0.00412371\n",
      "Epoch: 209 accuracy = 0.74539876\n",
      "Epoch: 210 cost = 0.00402518\n",
      "Epoch: 210 accuracy = 0.73916984\n",
      "Epoch: 211 cost = 0.00401595\n",
      "Epoch: 211 accuracy = 0.72986436\n",
      "Epoch: 212 cost = 0.00402126\n",
      "Epoch: 212 accuracy = 0.72391498\n",
      "Epoch: 213 cost = 0.00401346\n",
      "Epoch: 213 accuracy = 0.72272009\n",
      "Epoch: 214 cost = 0.00399471\n",
      "Epoch: 214 accuracy = 0.72447437\n",
      "Epoch: 215 cost = 0.00397344\n",
      "Epoch: 215 accuracy = 0.72790670\n",
      "Epoch: 216 cost = 0.00395341\n",
      "Epoch: 216 accuracy = 0.73352551\n",
      "Epoch: 217 cost = 0.00394649\n",
      "Epoch: 217 accuracy = 0.74257672\n",
      "Epoch: 218 cost = 0.00403387\n",
      "Epoch: 218 accuracy = 0.73787308\n",
      "Epoch: 219 cost = 0.00413344\n",
      "Epoch: 219 accuracy = 0.74542427\n",
      "Epoch: 220 cost = 0.00396215\n",
      "Epoch: 220 accuracy = 0.74811924\n",
      "Epoch: 221 cost = 0.00389015\n",
      "Epoch: 221 accuracy = 0.74486482\n",
      "Epoch: 222 cost = 0.00387798\n",
      "Epoch: 222 accuracy = 0.74066979\n",
      "Epoch: 223 cost = 0.00387714\n",
      "Epoch: 223 accuracy = 0.73596632\n",
      "Epoch: 224 cost = 0.00387255\n",
      "Epoch: 224 accuracy = 0.73329675\n",
      "Epoch: 225 cost = 0.00386313\n",
      "Epoch: 225 accuracy = 0.73144066\n",
      "Epoch: 226 cost = 0.00385207\n",
      "Epoch: 226 accuracy = 0.72999156\n",
      "Epoch: 227 cost = 0.00383910\n",
      "Epoch: 227 accuracy = 0.73014408\n",
      "Epoch: 228 cost = 0.00382326\n",
      "Epoch: 228 accuracy = 0.73177123\n",
      "Epoch: 229 cost = 0.00380505\n",
      "Epoch: 229 accuracy = 0.73423743\n",
      "Epoch: 230 cost = 0.00378719\n",
      "Epoch: 230 accuracy = 0.74143261\n",
      "Epoch: 231 cost = 0.00381655\n",
      "Epoch: 231 accuracy = 0.74361908\n",
      "Epoch: 232 cost = 0.00405744\n",
      "Epoch: 232 accuracy = 0.74100041\n",
      "Epoch: 233 cost = 0.00390115\n",
      "Epoch: 233 accuracy = 0.75038207\n",
      "Epoch: 234 cost = 0.00374666\n",
      "Epoch: 234 accuracy = 0.74842429\n",
      "Epoch: 235 cost = 0.00373063\n",
      "Epoch: 235 accuracy = 0.74651754\n",
      "Epoch: 236 cost = 0.00372906\n",
      "Epoch: 236 accuracy = 0.74580562\n",
      "Epoch: 237 cost = 0.00372688\n",
      "Epoch: 237 accuracy = 0.74555135\n",
      "Epoch: 238 cost = 0.00372163\n",
      "Epoch: 238 accuracy = 0.74605983\n",
      "Epoch: 239 cost = 0.00371510\n",
      "Epoch: 239 accuracy = 0.74728030\n",
      "Epoch: 240 cost = 0.00371318\n",
      "Epoch: 240 accuracy = 0.75000072\n",
      "Epoch: 241 cost = 0.00374438\n",
      "Epoch: 241 accuracy = 0.74717855\n",
      "Epoch: 242 cost = 0.00383124\n",
      "Epoch: 242 accuracy = 0.74590731\n",
      "Epoch: 243 cost = 0.00375500\n",
      "Epoch: 243 accuracy = 0.75190753\n",
      "Epoch: 244 cost = 0.00366324\n",
      "Epoch: 244 accuracy = 0.75010240\n",
      "Epoch: 245 cost = 0.00365535\n",
      "Epoch: 245 accuracy = 0.74262762\n",
      "Epoch: 246 cost = 0.00367372\n",
      "Epoch: 246 accuracy = 0.73718661\n",
      "Epoch: 247 cost = 0.00367027\n",
      "Epoch: 247 accuracy = 0.73746634\n",
      "Epoch: 248 cost = 0.00364313\n",
      "Epoch: 248 accuracy = 0.74082243\n",
      "Epoch: 249 cost = 0.00361424\n",
      "Epoch: 249 accuracy = 0.74517000\n",
      "Epoch: 250 cost = 0.00359940\n",
      "Epoch: 250 accuracy = 0.74926341\n",
      "Epoch: 251 cost = 0.00362632\n",
      "Epoch: 251 accuracy = 0.75020415\n",
      "Epoch: 252 cost = 0.00375461\n",
      "Epoch: 252 accuracy = 0.74682260\n",
      "Epoch: 253 cost = 0.00372209\n",
      "Epoch: 253 accuracy = 0.75340760\n",
      "Epoch: 254 cost = 0.00358808\n",
      "Epoch: 254 accuracy = 0.75297529\n",
      "Epoch: 255 cost = 0.00355668\n",
      "Epoch: 255 accuracy = 0.75134814\n",
      "Epoch: 256 cost = 0.00355599\n",
      "Epoch: 256 accuracy = 0.74806839\n",
      "Epoch: 257 cost = 0.00356171\n",
      "Epoch: 257 accuracy = 0.74534798\n",
      "Epoch: 258 cost = 0.00356394\n",
      "Epoch: 258 accuracy = 0.74321234\n",
      "Epoch: 259 cost = 0.00355658\n",
      "Epoch: 259 accuracy = 0.74275464\n",
      "Epoch: 260 cost = 0.00354078\n",
      "Epoch: 260 accuracy = 0.74438184\n",
      "Epoch: 261 cost = 0.00352097\n",
      "Epoch: 261 accuracy = 0.74725479\n",
      "Epoch: 262 cost = 0.00350221\n",
      "Epoch: 262 accuracy = 0.74982274\n",
      "Epoch: 263 cost = 0.00349844\n",
      "Epoch: 263 accuracy = 0.75264478\n",
      "Epoch: 264 cost = 0.00364500\n",
      "Epoch: 264 accuracy = 0.74483943\n",
      "Epoch: 265 cost = 0.00373177\n",
      "Epoch: 265 accuracy = 0.75450075\n",
      "Epoch: 266 cost = 0.00350599\n",
      "Epoch: 266 accuracy = 0.75564498\n",
      "Epoch: 267 cost = 0.00345356\n",
      "Epoch: 267 accuracy = 0.75561959\n",
      "Epoch: 268 cost = 0.00344833\n",
      "Epoch: 268 accuracy = 0.75483131\n",
      "Epoch: 269 cost = 0.00345225\n",
      "Epoch: 269 accuracy = 0.75330591\n",
      "Epoch: 270 cost = 0.00345724\n",
      "Epoch: 270 accuracy = 0.75246686\n",
      "Epoch: 271 cost = 0.00345380\n",
      "Epoch: 271 accuracy = 0.75244153\n",
      "Epoch: 272 cost = 0.00344112\n",
      "Epoch: 272 accuracy = 0.75249225\n",
      "Epoch: 273 cost = 0.00342954\n",
      "Epoch: 273 accuracy = 0.75150073\n",
      "Epoch: 274 cost = 0.00342496\n",
      "Epoch: 274 accuracy = 0.74939048\n",
      "Epoch: 275 cost = 0.00343516\n",
      "Epoch: 275 accuracy = 0.74593276\n",
      "Epoch: 276 cost = 0.00345646\n",
      "Epoch: 276 accuracy = 0.74735653\n",
      "Epoch: 277 cost = 0.00342086\n",
      "Epoch: 277 accuracy = 0.75419575\n",
      "Epoch: 278 cost = 0.00336371\n",
      "Epoch: 278 accuracy = 0.75912809\n",
      "Epoch: 279 cost = 0.00338731\n",
      "Epoch: 279 accuracy = 0.75577205\n",
      "Epoch: 280 cost = 0.00361635\n",
      "Epoch: 280 accuracy = 0.75160241\n",
      "Epoch: 281 cost = 0.00351949\n",
      "Epoch: 281 accuracy = 0.76121294\n",
      "Epoch: 282 cost = 0.00335023\n",
      "Epoch: 282 accuracy = 0.76362824\n",
      "Epoch: 283 cost = 0.00332032\n",
      "Epoch: 283 accuracy = 0.76406044\n",
      "Epoch: 284 cost = 0.00331519\n",
      "Epoch: 284 accuracy = 0.76403511\n",
      "Epoch: 285 cost = 0.00332185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 285 accuracy = 0.76385713\n",
      "Epoch: 286 cost = 0.00333960\n",
      "Epoch: 286 accuracy = 0.76276374\n",
      "Epoch: 287 cost = 0.00334862\n",
      "Epoch: 287 accuracy = 0.76357734\n",
      "Epoch: 288 cost = 0.00333264\n",
      "Epoch: 288 accuracy = 0.76461977\n",
      "Epoch: 289 cost = 0.00334090\n",
      "Epoch: 289 accuracy = 0.76271296\n",
      "Epoch: 290 cost = 0.00339114\n",
      "Epoch: 290 accuracy = 0.76268762\n",
      "Epoch: 291 cost = 0.00334486\n",
      "Epoch: 291 accuracy = 0.76828092\n",
      "Epoch: 292 cost = 0.00325874\n",
      "Epoch: 292 accuracy = 0.76868778\n",
      "Epoch: 293 cost = 0.00323848\n",
      "Epoch: 293 accuracy = 0.76489955\n",
      "Epoch: 294 cost = 0.00328197\n",
      "Epoch: 294 accuracy = 0.75856882\n",
      "Epoch: 295 cost = 0.00331274\n",
      "Epoch: 295 accuracy = 0.76052654\n",
      "Epoch: 296 cost = 0.00325556\n",
      "Epoch: 296 accuracy = 0.76477242\n",
      "Epoch: 297 cost = 0.00320277\n",
      "Epoch: 297 accuracy = 0.76761997\n",
      "Epoch: 298 cost = 0.00317546\n",
      "Epoch: 298 accuracy = 0.77145898\n",
      "Epoch: 299 cost = 0.00318340\n",
      "Epoch: 299 accuracy = 0.77003533\n",
      "Epoch: 300 cost = 0.00336016\n",
      "Epoch: 300 accuracy = 0.75925523\n",
      "Epoch: 301 cost = 0.00340661\n",
      "Epoch: 301 accuracy = 0.77097601\n",
      "Epoch: 302 cost = 0.00317612\n",
      "Epoch: 302 accuracy = 0.77593374\n",
      "Epoch: 303 cost = 0.00311690\n",
      "Epoch: 303 accuracy = 0.77570492\n",
      "Epoch: 304 cost = 0.00310507\n",
      "Epoch: 304 accuracy = 0.77476424\n",
      "Epoch: 305 cost = 0.00310603\n",
      "Epoch: 305 accuracy = 0.77415407\n",
      "Epoch: 306 cost = 0.00315020\n",
      "Epoch: 306 accuracy = 0.76975560\n",
      "Epoch: 307 cost = 0.00319046\n",
      "Epoch: 307 accuracy = 0.77130657\n",
      "Epoch: 308 cost = 0.00312277\n",
      "Epoch: 308 accuracy = 0.77110308\n",
      "Epoch: 309 cost = 0.00308567\n",
      "Epoch: 309 accuracy = 0.76980650\n",
      "Epoch: 310 cost = 0.00307341\n",
      "Epoch: 310 accuracy = 0.76807761\n",
      "Epoch: 311 cost = 0.00307311\n",
      "Epoch: 311 accuracy = 0.76474696\n",
      "Epoch: 312 cost = 0.00308847\n",
      "Epoch: 312 accuracy = 0.76240778\n",
      "Epoch: 313 cost = 0.00309948\n",
      "Epoch: 313 accuracy = 0.76489949\n",
      "Epoch: 314 cost = 0.00306175\n",
      "Epoch: 314 accuracy = 0.76652670\n",
      "Epoch: 315 cost = 0.00306102\n",
      "Epoch: 315 accuracy = 0.76459444\n",
      "Epoch: 316 cost = 0.00307574\n",
      "Epoch: 316 accuracy = 0.76802671\n",
      "Epoch: 317 cost = 0.00301037\n",
      "Epoch: 317 accuracy = 0.77257770\n",
      "Epoch: 318 cost = 0.00295937\n",
      "Epoch: 318 accuracy = 0.77745932\n",
      "Epoch: 319 cost = 0.00303059\n",
      "Epoch: 319 accuracy = 0.77206928\n",
      "Epoch: 320 cost = 0.00341816\n",
      "Epoch: 320 accuracy = 0.77156079\n",
      "Epoch: 321 cost = 0.00317905\n",
      "Epoch: 321 accuracy = 0.78333241\n",
      "Epoch: 322 cost = 0.00297100\n",
      "Epoch: 322 accuracy = 0.78356129\n",
      "Epoch: 323 cost = 0.00295331\n",
      "Epoch: 323 accuracy = 0.78251880\n",
      "Epoch: 324 cost = 0.00297029\n",
      "Epoch: 324 accuracy = 0.78058654\n",
      "Epoch: 325 cost = 0.00298612\n",
      "Epoch: 325 accuracy = 0.78033233\n",
      "Epoch: 326 cost = 0.00297766\n",
      "Epoch: 326 accuracy = 0.78244251\n",
      "Epoch: 327 cost = 0.00296160\n",
      "Epoch: 327 accuracy = 0.78483236\n",
      "Epoch: 328 cost = 0.00297222\n",
      "Epoch: 328 accuracy = 0.78460354\n",
      "Epoch: 329 cost = 0.00308514\n",
      "Epoch: 329 accuracy = 0.77791685\n",
      "Epoch: 330 cost = 0.00312779\n",
      "Epoch: 330 accuracy = 0.78635794\n",
      "Epoch: 331 cost = 0.00295217\n",
      "Epoch: 331 accuracy = 0.78775626\n",
      "Epoch: 332 cost = 0.00289508\n",
      "Epoch: 332 accuracy = 0.78340864\n",
      "Epoch: 333 cost = 0.00291774\n",
      "Epoch: 333 accuracy = 0.77712882\n",
      "Epoch: 334 cost = 0.00295477\n",
      "Epoch: 334 accuracy = 0.77639145\n",
      "Epoch: 335 cost = 0.00292407\n",
      "Epoch: 335 accuracy = 0.77918810\n",
      "Epoch: 336 cost = 0.00287749\n",
      "Epoch: 336 accuracy = 0.78297651\n",
      "Epoch: 337 cost = 0.00285863\n",
      "Epoch: 337 accuracy = 0.78742576\n",
      "Epoch: 338 cost = 0.00289858\n",
      "Epoch: 338 accuracy = 0.78549349\n",
      "Epoch: 339 cost = 0.00313045\n",
      "Epoch: 339 accuracy = 0.77801859\n",
      "Epoch: 340 cost = 0.00307603\n",
      "Epoch: 340 accuracy = 0.79019696\n",
      "Epoch: 341 cost = 0.00285149\n",
      "Epoch: 341 accuracy = 0.78846812\n",
      "Epoch: 342 cost = 0.00281232\n",
      "Epoch: 342 accuracy = 0.78470534\n",
      "Epoch: 343 cost = 0.00281792\n",
      "Epoch: 343 accuracy = 0.78167981\n",
      "Epoch: 344 cost = 0.00283466\n",
      "Epoch: 344 accuracy = 0.78058648\n",
      "Epoch: 345 cost = 0.00284466\n",
      "Epoch: 345 accuracy = 0.78198493\n",
      "Epoch: 346 cost = 0.00283403\n",
      "Epoch: 346 accuracy = 0.78706980\n",
      "Epoch: 347 cost = 0.00283232\n",
      "Epoch: 347 accuracy = 0.79042584\n",
      "Epoch: 348 cost = 0.00295766\n",
      "Epoch: 348 accuracy = 0.78213739\n",
      "Epoch: 349 cost = 0.00306384\n",
      "Epoch: 349 accuracy = 0.79149371\n",
      "Epoch: 350 cost = 0.00284609\n",
      "Epoch: 350 accuracy = 0.79261237\n",
      "Epoch: 351 cost = 0.00275080\n",
      "Epoch: 351 accuracy = 0.78958678\n",
      "Epoch: 352 cost = 0.00273887\n",
      "Epoch: 352 accuracy = 0.78592575\n",
      "Epoch: 353 cost = 0.00274729\n",
      "Epoch: 353 accuracy = 0.78290021\n",
      "Epoch: 354 cost = 0.00276424\n",
      "Epoch: 354 accuracy = 0.78170520\n",
      "Epoch: 355 cost = 0.00277375\n",
      "Epoch: 355 accuracy = 0.78300178\n",
      "Epoch: 356 cost = 0.00277982\n",
      "Epoch: 356 accuracy = 0.78818852\n",
      "Epoch: 357 cost = 0.00282644\n",
      "Epoch: 357 accuracy = 0.78923088\n",
      "Epoch: 358 cost = 0.00301593\n",
      "Epoch: 358 accuracy = 0.78712064\n",
      "Epoch: 359 cost = 0.00292723\n",
      "Epoch: 359 accuracy = 0.79601932\n",
      "Epoch: 360 cost = 0.00271040\n",
      "Epoch: 360 accuracy = 0.79317164\n",
      "Epoch: 361 cost = 0.00266609\n",
      "Epoch: 361 accuracy = 0.79062921\n",
      "Epoch: 362 cost = 0.00266118\n",
      "Epoch: 362 accuracy = 0.78780711\n",
      "Epoch: 363 cost = 0.00266662\n",
      "Epoch: 363 accuracy = 0.78564602\n",
      "Epoch: 364 cost = 0.00268570\n",
      "Epoch: 364 accuracy = 0.78236622\n",
      "Epoch: 365 cost = 0.00272385\n",
      "Epoch: 365 accuracy = 0.77684903\n",
      "Epoch: 366 cost = 0.00282953\n",
      "Epoch: 366 accuracy = 0.76985729\n",
      "Epoch: 367 cost = 0.00286185\n",
      "Epoch: 367 accuracy = 0.78132385\n",
      "Epoch: 368 cost = 0.00266367\n",
      "Epoch: 368 accuracy = 0.78910375\n",
      "Epoch: 369 cost = 0.00260124\n",
      "Epoch: 369 accuracy = 0.78996819\n",
      "Epoch: 370 cost = 0.00261524\n",
      "Epoch: 370 accuracy = 0.79197675\n",
      "Epoch: 371 cost = 0.00273455\n",
      "Epoch: 371 accuracy = 0.79014617\n",
      "Epoch: 372 cost = 0.00297014\n",
      "Epoch: 372 accuracy = 0.78923088\n",
      "Epoch: 373 cost = 0.00285594\n",
      "Epoch: 373 accuracy = 0.79840916\n",
      "Epoch: 374 cost = 0.00263553\n",
      "Epoch: 374 accuracy = 0.79601926\n",
      "Epoch: 375 cost = 0.00259498\n",
      "Epoch: 375 accuracy = 0.79385805\n",
      "Epoch: 376 cost = 0.00260480\n",
      "Epoch: 376 accuracy = 0.79034960\n",
      "Epoch: 377 cost = 0.00262015\n",
      "Epoch: 377 accuracy = 0.78981566\n",
      "Epoch: 378 cost = 0.00261646\n",
      "Epoch: 378 accuracy = 0.79065466\n",
      "Epoch: 379 cost = 0.00259994\n",
      "Epoch: 379 accuracy = 0.79273945\n",
      "Epoch: 380 cost = 0.00259712\n",
      "Epoch: 380 accuracy = 0.79599380\n",
      "Epoch: 381 cost = 0.00269782\n",
      "Epoch: 381 accuracy = 0.78933257\n",
      "Epoch: 382 cost = 0.00296136\n",
      "Epoch: 382 accuracy = 0.79373103\n",
      "Epoch: 383 cost = 0.00274350\n",
      "Epoch: 383 accuracy = 0.79904479\n",
      "Epoch: 384 cost = 0.00254677\n",
      "Epoch: 384 accuracy = 0.79634976\n",
      "Epoch: 385 cost = 0.00252042\n",
      "Epoch: 385 accuracy = 0.79464638\n",
      "Epoch: 386 cost = 0.00252609\n",
      "Epoch: 386 accuracy = 0.79134107\n",
      "Epoch: 387 cost = 0.00254381\n",
      "Epoch: 387 accuracy = 0.78816301\n",
      "Epoch: 388 cost = 0.00258309\n",
      "Epoch: 388 accuracy = 0.78035772\n",
      "Epoch: 389 cost = 0.00272267\n",
      "Epoch: 389 accuracy = 0.77555239\n",
      "Epoch: 390 cost = 0.00273204\n",
      "Epoch: 390 accuracy = 0.78620541\n",
      "Epoch: 391 cost = 0.00254496\n",
      "Epoch: 391 accuracy = 0.79253608\n",
      "Epoch: 392 cost = 0.00248563\n",
      "Epoch: 392 accuracy = 0.79289210\n",
      "Epoch: 393 cost = 0.00248450\n",
      "Epoch: 393 accuracy = 0.79289198\n",
      "Epoch: 394 cost = 0.00250416\n",
      "Epoch: 394 accuracy = 0.79337502\n",
      "Epoch: 395 cost = 0.00255746\n",
      "Epoch: 395 accuracy = 0.79563785\n",
      "Epoch: 396 cost = 0.00281192\n",
      "Epoch: 396 accuracy = 0.78869700\n",
      "Epoch: 397 cost = 0.00283168\n",
      "Epoch: 397 accuracy = 0.80156183\n",
      "Epoch: 398 cost = 0.00252494\n",
      "Epoch: 398 accuracy = 0.79978210\n",
      "Epoch: 399 cost = 0.00245004\n",
      "Epoch: 399 accuracy = 0.79856175\n",
      "Epoch: 400 cost = 0.00244250\n",
      "Epoch: 400 accuracy = 0.79731596\n"
     ]
    }
   ],
   "source": [
    "# Start Training\n",
    "# Start a new TF session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Run the initializer\n",
    "sess.run(init)\n",
    "batch_size = 64\n",
    "num_batch = 614\n",
    "\n",
    "# Training\n",
    "for i in range(0,400):\n",
    "    k = 0 \n",
    "    # Prepare Data\n",
    "    # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "    avg_cost = 0\n",
    "    for j in (0,num_batch):\n",
    "        batch_x = X_train1[k:k+batch_size,:]\n",
    "        batch_y = y_train11[k:k+batch_size,:]\n",
    "        k += 64\n",
    "        #print(j)\n",
    "\n",
    "    # Run optimization op (backprop) and cost op (to get loss value)\n",
    "        _, l = sess.run([optimizer, loss_total], feed_dict={X: batch_x, Y: batch_y})\n",
    "        avg_cost += l / num_batch\n",
    "    \n",
    "    print(\"Epoch:\", (i + 1), \"cost =\", \"{:.8f}\".format(avg_cost))\n",
    "    print(\"Epoch:\", (i + 1), \"accuracy =\", \"{:.8f}\".format(sess.run(accuracy, feed_dict={X: X_train1, Y: y_train11})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68830943]\n"
     ]
    }
   ],
   "source": [
    "# on 200 epoch\n",
    "\n",
    "print(sess.run([accuracy], feed_dict={X: X_test, Y: y_test11}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46640238]\n"
     ]
    }
   ],
   "source": [
    "# on 400 epoch\n",
    "\n",
    "print(sess.run([accuracy], feed_dict={X: X_test, Y: y_test11}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
