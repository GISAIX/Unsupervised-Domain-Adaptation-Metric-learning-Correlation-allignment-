{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import numpy\n",
    "import PIL\n",
    "from PIL import Image\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Lambda\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "\n",
    "\n",
    "def euclidean_distance(x, y):\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def conc(vects):\n",
    "    x, y = vects\n",
    "    conc1 = concatenate([x,y])\n",
    "    return conc1\n",
    "\n",
    "def conc_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],32)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    x = y_pred[:,0:128]\n",
    "    y = y_pred[:,128:268]\n",
    "    y_pred1 = euclidean_distance(x,y)\n",
    "    p = x\n",
    "    q = y\n",
    "    p = K.clip(p, K.epsilon(), 1)\n",
    "    q = K.clip(q, K.epsilon(), 1)\n",
    "    #y_true1 = y_true[:,0]\n",
    "    #y_true1 = K.reshape(y_true1,(-1,))\n",
    "    #print(y_true1)\n",
    "    #tr_same = y_true[:,1]\n",
    "    #tr_same = K.reshape(tr_same, (-1,))\n",
    "    y_true1 = y_true\n",
    "    tr_same = K.round(y_true/3)\n",
    "    margin = 1\n",
    "    test = 0.001*K.sum(p*K.abs(K.log(p)-K.log(q)), axis=1)\n",
    "\n",
    "    return K.mean((1-tr_same)*(y_true1 * K.square(y_pred1) + (1 - y_true1) * K.square(K.maximum(margin - y_pred1, 0)))\n",
    "                 + (tr_same)*test)\n",
    "\n",
    "def triplet_loss(y_true, y_pred):\n",
    "    x = y_pred[:,0:32]\n",
    "    y = y_pred[:,32:64]\n",
    "    y_pred1 = euclidean_distance(x,y)\n",
    "    y_true1 = y_true\n",
    "    margin = 1\n",
    "    return K.mean(y_true1 * K.square(y_pred1) + (1 - y_true1) * K.square(K.maximum(margin - y_pred1, 0)))\n",
    "\n",
    "def coral_loss(y_true, y_pred):\n",
    "    x = y_pred[:,0:32]\n",
    "    y = y_pred[:,32:64]\n",
    "    n = 32.0\n",
    "    mul1 = K.dot(K.transpose(x),x)\n",
    "    one = x*0+1\n",
    "    mul2 = K.dot(K.transpose(one), x)\n",
    "    sub = K.dot(K.transpose(mul2), mul2)\n",
    "    source = (mul1 - (sub)/n)/(n-1)\n",
    "    source = K.abs(source)\n",
    "    source = K.clip(source, K.epsilon(),10000)\n",
    "    source1 = K.log(source)\n",
    "    \n",
    "    mul11 = K.dot(K.transpose(y),y)\n",
    "    mul21 = K.dot(K.transpose(one), y)\n",
    "    sub1 = K.dot(K.transpose(mul2), mul2)\n",
    "    n = float(n)\n",
    "    target = (mul11 - (sub1)/n)/(n-1)\n",
    "    target = K.abs(target)\n",
    "    target = K.clip(target, K.epsilon(),10000)\n",
    "    target1 = K.log(target)\n",
    "    \n",
    "    return (K.sum(K.dot((source1-target1),(source1-target1)))/(4*32*32.0))\n",
    "       \n",
    "    \n",
    "\n",
    "def create_pairs(x, digit_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(7)]) - 1\n",
    "    for d in range(7):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1,7)\n",
    "            dn = (d + inc) % 7\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "def create_addi_pairs(x, y):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    for i in range(0,1000):\n",
    "        k1 = random.randrange(0,x.shape[0])\n",
    "        for j in range(0,10):\n",
    "            k2 = random.randrange(0, y.shape[0])\n",
    "            pairs+= [[x[k1],y[k2]]]\n",
    "            labels += [3]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "             \n",
    "            \n",
    "def create_base_network():\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    seq = Sequential()\n",
    "    seq.add(Dense(64, input_shape=(64,), activation='relu'))\n",
    "    #seq.add(Dense(64, activation='relu'))\n",
    "    seq.add(Dense(32, activation='relu'))\n",
    "    seq.add(Dense(32, activation='relu'))\n",
    "    return seq\n",
    "\n",
    "\n",
    "def compute_accuracy(predictions, labels):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return labels[predictions.ravel() < 0.5].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1096, 715, 102)\n",
      "(1096, 715)\n",
      "(72933, 102)\n",
      "(72933,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniruddha/anaconda3/envs/tensorflow/lib/python3.5/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint16 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72933, 64)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('/home/aniruddha/deep-learning-projects/Siamese_Networks/Dataset/PaviaCentre.mat')\n",
    "arr = mat['pavia']\n",
    "arr = np.array(arr)\n",
    "print(arr.shape)\n",
    "\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat('/home/aniruddha/deep-learning-projects/Siamese_Networks/Dataset/PaviaCentre_gt.mat')\n",
    "arr1 = mat['pavia_gt']\n",
    "arr1 = np.array(arr1)\n",
    "print(arr1.shape)\n",
    "\n",
    "a=[]\n",
    "label=[]\n",
    "k=0\n",
    "for i in range(0,arr1.shape[0]):\n",
    "    for j in range(0,arr1[i].shape[0]):\n",
    "        a.append(arr[i][j])\n",
    "        label.append(arr1[i][j])\n",
    "        \n",
    "a=np.array(a)\n",
    "label=np.array(label)\n",
    "\n",
    "X_train=[]\n",
    "y_train=[]\n",
    "for i in range (0,a.shape[0]):\n",
    "    if(label[i]==2):\n",
    "        y_train.append(0)\n",
    "    if(label[i]==3):\n",
    "        y_train.append(1)\n",
    "    if(label[i]==4):\n",
    "        y_train.append(2)\n",
    "    if(label[i]==5):\n",
    "        y_train.append(3)\n",
    "    if(label[i]==7):\n",
    "        y_train.append(4)\n",
    "    if(label[i]==8):\n",
    "        y_train.append(5)\n",
    "    if(label[i]==9):\n",
    "        y_train.append(6)\n",
    "    if (label[i]==2 or label[i]==3 or label[i]==4 or label[i]==5 or label[i]==7 or label[i]==8 or label[i]==9):\n",
    "        X_train.append(a[i])\n",
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state = 0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=64)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(label.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(610, 340)\n",
      "(207400, 103)\n",
      "(207400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniruddha/anaconda3/envs/tensorflow/lib/python3.5/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint16 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39332, 64)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('/home/aniruddha/deep-learning-projects/Siamese_Networks/Dataset/PaviaU.mat')\n",
    "arr = mat['paviaU']\n",
    "arr = np.array(arr)\n",
    "\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat('/home/aniruddha/deep-learning-projects/Siamese_Networks/Dataset/PaviaU_gt.mat')\n",
    "arr1 = mat['paviaU_gt']\n",
    "arr1 = np.array(arr1)\n",
    "print(arr1.shape)\n",
    "\n",
    "a=[]\n",
    "label=[]\n",
    "k=0\n",
    "for i in range(0,arr1.shape[0]):\n",
    "    for j in range(0,arr1[i].shape[0]):\n",
    "        a.append(arr[i][j])\n",
    "        label.append(arr1[i][j])\n",
    "        \n",
    "a=np.array(a)\n",
    "label=np.array(label)\n",
    "print(a.shape)\n",
    "print(label.shape)\n",
    "\n",
    "X_train1=[]\n",
    "y_train1=[]\n",
    "for i in range (0,a.shape[0]):\n",
    "    if(label[i]==4):\n",
    "        y_train1.append(0)\n",
    "    if(label[i]==1):\n",
    "        y_train1.append(1)\n",
    "    if(label[i]==8):\n",
    "        y_train1.append(2)\n",
    "    if(label[i]==7):\n",
    "        y_train1.append(3)\n",
    "    if(label[i]==9):\n",
    "        y_train1.append(4)\n",
    "    if(label[i]==2):\n",
    "        y_train1.append(5)\n",
    "    if(label[i]==6):\n",
    "        y_train1.append(6)\n",
    "    if (label[i]==4 or label[i]==1 or label[i]==8 or label[i]==7 or label[i]==9 or label[i]==2 or label[i]==6):\n",
    "        X_train1.append(a[i])\n",
    "X_train1=np.array(X_train1)\n",
    "y_train1=np.array(y_train1)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X_train1, y_train1 = shuffle(X_train1, y_train1, random_state = 0)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train1 = StandardScaler().fit_transform(X_train1)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=64)\n",
    "X_train1 = pca.fit_transform(X_train1)\n",
    "print(X_train1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.423585702771796\n",
      "104.56701566525479\n"
     ]
    }
   ],
   "source": [
    "print(X_train.max())\n",
    "print(X_train1.max())\n",
    "X_train=X_train.astype('float32')\n",
    "X_train1=X_train1.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-19.61208\n",
      "-19.46586\n"
     ]
    }
   ],
   "source": [
    "print(X_train.min())\n",
    "print(X_train1.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train/100\n",
    "X_train1=X_train1/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39332, 64)\n",
      "(22933, 64)\n"
     ]
    }
   ],
   "source": [
    "X_test=X_train[50000:72933,:]\n",
    "y_test=y_train[50000:72933]\n",
    "X_train=X_train[0:50000,:]\n",
    "y_train=y_train[0:50000]\n",
    "\n",
    "print(X_train1.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47423583\n",
      "1.0456702\n",
      "0.36481896\n",
      "-0.19607832\n",
      "-0.1946586\n"
     ]
    }
   ],
   "source": [
    "print((X_train).max())\n",
    "print(abs(X_train1).max())\n",
    "print(abs(X_test).max())\n",
    "print(X_train.min())\n",
    "print(X_train1.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_indices = [np.where(y_train1 == i)[0] for i in range(7)]\n",
    "tr_pairs, tr_y = create_pairs(X_train1, digit_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr1_pairs, tr1_y = create_addi_pairs(X_train1, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13244, 2, 64)\n",
      "(10000, 2, 64)\n"
     ]
    }
   ],
   "source": [
    "print(tr_pairs.shape)\n",
    "print(tr1_pairs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 64)\n",
      "(?, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniruddha/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"la...)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# network definition\n",
    "input_dim=X_train.shape[1:]\n",
    "base_network = create_base_network()\n",
    "\n",
    "input_a = Input(shape=input_dim)\n",
    "input_b = Input(shape=input_dim)\n",
    "\n",
    "#input_a=K.reshape(input_a,(28,28,1))\n",
    "#input_b=K.reshape(input_b,(28,28,1))\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "print(input_b.shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(conc, output_shape=conc_shape)([processed_a, processed_b])\n",
    "print(distance.shape)\n",
    "\n",
    "model = Model(input=[input_a, input_b], output=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniruddha/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_model = Model(input = input_a, output = processed_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"191pt\" viewBox=\"0.00 0.00 276.00 191.00\" width=\"276pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 187)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-187 272,-187 272,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139640264104592 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139640264104592</title>\n",
       "<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 125,-182.5 125,-146.5 0,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-160.8\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139640264105320 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139640264105320</title>\n",
       "<polygon fill=\"none\" points=\"59,-73.5 59,-109.5 208,-109.5 208,-73.5 59,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133.5\" y=\"-87.8\">sequential_1: Sequential</text>\n",
       "</g>\n",
       "<!-- 139640264104592&#45;&gt;139640264105320 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139640264104592-&gt;139640264105320</title>\n",
       "<path d=\"M79.6871,-146.313C88.5826,-137.417 99.5906,-126.409 109.328,-116.672\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"111.875,-119.075 116.471,-109.529 106.925,-114.125 111.875,-119.075\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139640263927568 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139640263927568</title>\n",
       "<polygon fill=\"none\" points=\"143,-146.5 143,-182.5 268,-182.5 268,-146.5 143,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-160.8\">input_2: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139640263927568&#45;&gt;139640264105320 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139640263927568-&gt;139640264105320</title>\n",
       "<path d=\"M188.071,-146.313C179.05,-137.417 167.887,-126.409 158.012,-116.672\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"160.347,-114.058 150.769,-109.529 155.432,-119.042 160.347,-114.058\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139640264120808 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139640264120808</title>\n",
       "<polygon fill=\"none\" points=\"72,-0.5 72,-36.5 195,-36.5 195,-0.5 72,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133.5\" y=\"-14.8\">lambda_1: Lambda</text>\n",
       "</g>\n",
       "<!-- 139640264105320&#45;&gt;139640264120808 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139640264105320-&gt;139640264120808</title>\n",
       "<path d=\"M133.5,-73.3129C133.5,-65.2895 133.5,-55.5475 133.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"137,-46.5288 133.5,-36.5288 130,-46.5289 137,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13244, 64)\n",
      "(13244, 64)\n",
      "(13244,)\n"
     ]
    }
   ],
   "source": [
    "print(tr_pairs[:,0].shape)\n",
    "print(tr_pairs[:,1].shape)\n",
    "print(tr_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniruddha/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:7: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 5s 391us/step - loss: 0.1402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniruddha/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:9: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 65us/step - loss: 0.0313\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 56us/step - loss: 0.0863\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 64us/step - loss: 1.5098e-06\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 60us/step - loss: 0.0851\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 68us/step - loss: 2.0988e-07\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 62us/step - loss: 0.0795\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 70us/step - loss: 1.1944e-07\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 64us/step - loss: 0.0758\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 78us/step - loss: 6.4435e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 73us/step - loss: 0.0732\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 79us/step - loss: 3.7007e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 80us/step - loss: 0.0680\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 81us/step - loss: 3.4228e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 73us/step - loss: 0.0720\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 87us/step - loss: 2.6466e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 78us/step - loss: 0.0650\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 100us/step - loss: 2.5194e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 85us/step - loss: 0.0634\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 111us/step - loss: 2.7435e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 91us/step - loss: 0.0620\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 99us/step - loss: 1.6865e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 83us/step - loss: 0.0629\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 103us/step - loss: 1.2859e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 88us/step - loss: 0.0698\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 109us/step - loss: 1.4794e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 88us/step - loss: 0.0613\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 111us/step - loss: 1.8001e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 93us/step - loss: 0.0605\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 114us/step - loss: 1.2027e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 97us/step - loss: 0.0661\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 117us/step - loss: 1.3612e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 100us/step - loss: 0.0610\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 122us/step - loss: 1.1381e-08\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 102us/step - loss: 0.0589\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 126us/step - loss: 9.1277e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 107us/step - loss: 0.0619\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 132us/step - loss: 6.9468e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 1s 109us/step - loss: 0.0584\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 135us/step - loss: 9.9704e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 115us/step - loss: 0.0584\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 5.6164e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 147us/step - loss: 0.0939\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 9.0201e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 116us/step - loss: 0.0662\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 147us/step - loss: 9.5854e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 140us/step - loss: 0.0585\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 180us/step - loss: 4.5783e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 145us/step - loss: 0.0579\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 180us/step - loss: 7.6882e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 152us/step - loss: 0.0568\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 187us/step - loss: 5.8351e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 153us/step - loss: 0.0569\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 192us/step - loss: 3.8017e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 164us/step - loss: 0.0738\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 179us/step - loss: 5.0975e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 141us/step - loss: 0.0625\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 187us/step - loss: 4.2145e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 138us/step - loss: 0.0622\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 173us/step - loss: 3.4207e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 142us/step - loss: 0.0595\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 175us/step - loss: 3.0894e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 152us/step - loss: 0.0584\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 206us/step - loss: 2.6323e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 186us/step - loss: 0.0569\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 229us/step - loss: 2.4525e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 154us/step - loss: 0.0569\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 227us/step - loss: 2.1132e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 169us/step - loss: 0.0747\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 206us/step - loss: 1.9019e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 149us/step - loss: 0.0615\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 201us/step - loss: 1.5918e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 147us/step - loss: 0.0670\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 187us/step - loss: 1.6237e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 158us/step - loss: 0.0577\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 193us/step - loss: 1.5158e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 152us/step - loss: 0.0524\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 202us/step - loss: 1.8597e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 171us/step - loss: 0.0531\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 209us/step - loss: 9.0652e-10\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 167us/step - loss: 0.0718\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 227us/step - loss: 1.3675e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 3s 193us/step - loss: 0.0588\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 230us/step - loss: 1.4689e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 3s 198us/step - loss: 0.0526\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 246us/step - loss: 1.1077e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 186us/step - loss: 0.0516\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 247us/step - loss: 1.5599e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 2s 178us/step - loss: 0.0505\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 230us/step - loss: 1.4918e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 3s 198us/step - loss: 0.0510\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 233us/step - loss: 1.0452e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 3s 201us/step - loss: 0.0631\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 3s 295us/step - loss: 1.6667e-09\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13244/13244 [==============================] - 3s 259us/step - loss: 0.0560\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 3s 298us/step - loss: 1.2218e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 3s 233us/step - loss: 0.0538\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 3s 268us/step - loss: 1.5084e-09\n",
      "Epoch 1/1\n",
      "13244/13244 [==============================] - 3s 208us/step - loss: 0.0501\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 247us/step - loss: 1.0718e-09\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "from keras import optimizers\n",
    "#sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "rms = RMSprop()\n",
    "for i in range(0,50):\n",
    "     model.compile(loss=triplet_loss, optimizer=rms)\n",
    "     model.fit([tr_pairs[:,0], tr_pairs[:, 1]], tr_y, batch_size=64, nb_epoch=1)\n",
    "     model.compile(loss=coral_loss, optimizer=rms)\n",
    "     model.fit([tr1_pairs[:,0], tr1_pairs[:, 1]], tr1_y, batch_size=64, nb_epoch=1)\n",
    "     \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         4.965361  13.302396   6.320362  10.606984  15.5667095\n",
      " 15.979755   9.913061   9.64227    0.        15.32056    1.6860005\n",
      "  5.518911   9.726227  12.172305   7.5437403  0.        11.856464\n",
      "  1.0385636  5.3553824 14.767351   5.968116  11.950812  15.275465\n",
      " 15.356604  14.776543   8.37546    6.332607   8.070862   9.592548\n",
      " 15.130781   4.532213 ]\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "processed=test_model.predict(X_train1)\n",
    "print(processed[200])\n",
    "print(processed[100].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 7)\n",
      "(39332, 7)\n",
      "(22933, 7)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "y_tr = np_utils.to_categorical(y_train)\n",
    "y_tr1 = np_utils.to_categorical(y_train1)\n",
    "y_te = np_utils.to_categorical(y_test)\n",
    "num_classes = 7\n",
    "print(y_tr.shape)\n",
    "print(y_tr1.shape)\n",
    "print(y_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pixels = 32\n",
    "# define baseline model\n",
    "def baseline_model1():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(32, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32)\n",
      "(39332, 32)\n",
      "(22933, 32)\n"
     ]
    }
   ],
   "source": [
    "processed_train = test_model.predict(X_train)\n",
    "processed_train1 = test_model.predict(X_train1)\n",
    "processed_test = test_model.predict(X_test)\n",
    "print(processed_train.shape)\n",
    "print(processed_train1.shape)\n",
    "print(processed_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39332 samples, validate on 50000 samples\n",
      "Epoch 1/100\n",
      "39332/39332 [==============================] - 4s 104us/step - loss: 1.5566 - acc: 0.4741 - val_loss: 1.6217 - val_acc: 0.5872\n",
      "Epoch 2/100\n",
      "39332/39332 [==============================] - 2s 59us/step - loss: 1.5436 - acc: 0.4741 - val_loss: 1.6176 - val_acc: 0.5872\n",
      "Epoch 3/100\n",
      "39332/39332 [==============================] - 2s 56us/step - loss: 1.5443 - acc: 0.4741 - val_loss: 1.5919 - val_acc: 0.5872\n",
      "Epoch 4/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.5441 - acc: 0.4741 - val_loss: 1.6173 - val_acc: 0.5872\n",
      "Epoch 5/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.5442 - acc: 0.4741 - val_loss: 1.6178 - val_acc: 0.5872\n",
      "Epoch 6/100\n",
      "39332/39332 [==============================] - 2s 50us/step - loss: 1.5436 - acc: 0.4741 - val_loss: 1.6277 - val_acc: 0.5872\n",
      "Epoch 7/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.5438 - acc: 0.4741 - val_loss: 1.6440 - val_acc: 0.5872\n",
      "Epoch 8/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.5436 - acc: 0.4741 - val_loss: 1.6075 - val_acc: 0.5872\n",
      "Epoch 9/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.5433 - acc: 0.4741 - val_loss: 1.6354 - val_acc: 0.5872\n",
      "Epoch 10/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.5433 - acc: 0.4741 - val_loss: 1.6391 - val_acc: 0.5872\n",
      "Epoch 11/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.5439 - acc: 0.4741 - val_loss: 1.6434 - val_acc: 0.5872\n",
      "Epoch 12/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.5437 - acc: 0.4741 - val_loss: 1.6216 - val_acc: 0.5872\n",
      "Epoch 13/100\n",
      "39332/39332 [==============================] - 2s 49us/step - loss: 1.5434 - acc: 0.4741 - val_loss: 1.6352 - val_acc: 0.5872\n",
      "Epoch 14/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.5434 - acc: 0.4741 - val_loss: 1.6393 - val_acc: 0.5872\n",
      "Epoch 15/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.5434 - acc: 0.4741 - val_loss: 1.6202 - val_acc: 0.5872\n",
      "Epoch 16/100\n",
      "39332/39332 [==============================] - 2s 49us/step - loss: 1.5440 - acc: 0.4741 - val_loss: 1.6365 - val_acc: 0.5872\n",
      "Epoch 17/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.5434 - acc: 0.4741 - val_loss: 1.6258 - val_acc: 0.5872\n",
      "Epoch 18/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.5437 - acc: 0.4741 - val_loss: 1.6344 - val_acc: 0.5872\n",
      "Epoch 19/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.5436 - acc: 0.4741 - val_loss: 1.6529 - val_acc: 0.5872\n",
      "Epoch 20/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.5431 - acc: 0.4741 - val_loss: 1.6303 - val_acc: 0.5872\n",
      "Epoch 21/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.5431 - acc: 0.4741 - val_loss: 1.6270 - val_acc: 0.5872\n",
      "Epoch 22/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.5431 - acc: 0.4741 - val_loss: 1.6327 - val_acc: 0.5872\n",
      "Epoch 23/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.5432 - acc: 0.4741 - val_loss: 1.6294 - val_acc: 0.5872\n",
      "Epoch 24/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.5430 - acc: 0.4741 - val_loss: 1.6267 - val_acc: 0.5872\n",
      "Epoch 25/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.5433 - acc: 0.4741 - val_loss: 1.6063 - val_acc: 0.5872\n",
      "Epoch 26/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.5429 - acc: 0.4741 - val_loss: 1.6271 - val_acc: 0.5872\n",
      "Epoch 27/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.5426 - acc: 0.4741 - val_loss: 1.6210 - val_acc: 0.5872\n",
      "Epoch 28/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.5426 - acc: 0.4741 - val_loss: 1.6160 - val_acc: 0.5872\n",
      "Epoch 29/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.5428 - acc: 0.4741 - val_loss: 1.6303 - val_acc: 0.5872\n",
      "Epoch 30/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.5424 - acc: 0.4741 - val_loss: 1.6387 - val_acc: 0.5872\n",
      "Epoch 31/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.5419 - acc: 0.4741 - val_loss: 1.6427 - val_acc: 0.5872\n",
      "Epoch 32/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.5416 - acc: 0.4741 - val_loss: 1.6366 - val_acc: 0.5872\n",
      "Epoch 33/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.5402 - acc: 0.4741 - val_loss: 1.6356 - val_acc: 0.5872\n",
      "Epoch 34/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.5383 - acc: 0.4741 - val_loss: 1.6319 - val_acc: 0.5872\n",
      "Epoch 35/100\n",
      "39332/39332 [==============================] - 2s 49us/step - loss: 1.5330 - acc: 0.4741 - val_loss: 1.6096 - val_acc: 0.5872\n",
      "Epoch 36/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.5277 - acc: 0.4741 - val_loss: 1.6299 - val_acc: 0.5872\n",
      "Epoch 37/100\n",
      "39332/39332 [==============================] - 2s 54us/step - loss: 1.5150 - acc: 0.4741 - val_loss: 1.6393 - val_acc: 0.5872\n",
      "Epoch 38/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.4926 - acc: 0.4741 - val_loss: 1.6787 - val_acc: 0.5872\n",
      "Epoch 39/100\n",
      "39332/39332 [==============================] - 2s 49us/step - loss: 1.4674 - acc: 0.4741 - val_loss: 1.6819 - val_acc: 0.5872\n",
      "Epoch 40/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.4364 - acc: 0.4741 - val_loss: 1.6647 - val_acc: 0.5872\n",
      "Epoch 41/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.3998 - acc: 0.4740 - val_loss: 1.6917 - val_acc: 0.5866\n",
      "Epoch 42/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.3733 - acc: 0.4747 - val_loss: 1.6988 - val_acc: 0.5810\n",
      "Epoch 43/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.3498 - acc: 0.4747 - val_loss: 1.7912 - val_acc: 0.5823\n",
      "Epoch 44/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.3357 - acc: 0.4754 - val_loss: 1.7571 - val_acc: 0.5712\n",
      "Epoch 45/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.3202 - acc: 0.4754 - val_loss: 1.9511 - val_acc: 0.5817\n",
      "Epoch 46/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.3225 - acc: 0.4757 - val_loss: 2.0117 - val_acc: 0.5809\n",
      "Epoch 47/100\n",
      "39332/39332 [==============================] - 2s 45us/step - loss: 1.3073 - acc: 0.4763 - val_loss: 1.8473 - val_acc: 0.5519\n",
      "Epoch 48/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.3050 - acc: 0.4752 - val_loss: 1.9145 - val_acc: 0.5709\n",
      "Epoch 49/100\n",
      "39332/39332 [==============================] - 2s 59us/step - loss: 1.3082 - acc: 0.4741 - val_loss: 2.0860 - val_acc: 0.5772\n",
      "Epoch 50/100\n",
      "39332/39332 [==============================] - 2s 52us/step - loss: 1.3014 - acc: 0.4754 - val_loss: 2.0161 - val_acc: 0.5756\n",
      "Epoch 51/100\n",
      "39332/39332 [==============================] - 2s 44us/step - loss: 1.3100 - acc: 0.4759 - val_loss: 1.9530 - val_acc: 0.5790\n",
      "Epoch 52/100\n",
      "39332/39332 [==============================] - 2s 50us/step - loss: 1.3005 - acc: 0.4793 - val_loss: 2.0534 - val_acc: 0.5778\n",
      "Epoch 53/100\n",
      "39332/39332 [==============================] - 2s 50us/step - loss: 1.2992 - acc: 0.4765 - val_loss: 2.0296 - val_acc: 0.5785\n",
      "Epoch 54/100\n",
      "39332/39332 [==============================] - 2s 44us/step - loss: 1.2908 - acc: 0.4776 - val_loss: 2.1481 - val_acc: 0.5755\n",
      "Epoch 55/100\n",
      "39332/39332 [==============================] - 2s 42us/step - loss: 1.2945 - acc: 0.4776 - val_loss: 1.9745 - val_acc: 0.5677\n",
      "Epoch 56/100\n",
      "39332/39332 [==============================] - 2s 41us/step - loss: 1.2910 - acc: 0.4771 - val_loss: 2.2805 - val_acc: 0.5774\n",
      "Epoch 57/100\n",
      "39332/39332 [==============================] - 3s 68us/step - loss: 1.2936 - acc: 0.4756 - val_loss: 2.0781 - val_acc: 0.5741\n",
      "Epoch 58/100\n",
      "39332/39332 [==============================] - 3s 65us/step - loss: 1.2945 - acc: 0.4752 - val_loss: 2.0159 - val_acc: 0.5632\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.2970 - acc: 0.4743 - val_loss: 2.1236 - val_acc: 0.5707\n",
      "Epoch 60/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.2957 - acc: 0.4728 - val_loss: 2.0029 - val_acc: 0.5641\n",
      "Epoch 61/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.2902 - acc: 0.4770 - val_loss: 1.9803 - val_acc: 0.5470\n",
      "Epoch 62/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.2836 - acc: 0.4772 - val_loss: 2.0640 - val_acc: 0.5680\n",
      "Epoch 63/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.2884 - acc: 0.4748 - val_loss: 2.1910 - val_acc: 0.5736\n",
      "Epoch 64/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.2859 - acc: 0.4741 - val_loss: 2.1412 - val_acc: 0.5728\n",
      "Epoch 65/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.2937 - acc: 0.4741 - val_loss: 2.0093 - val_acc: 0.5444\n",
      "Epoch 66/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.2882 - acc: 0.4757 - val_loss: 2.0315 - val_acc: 0.5568\n",
      "Epoch 67/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.2877 - acc: 0.4737 - val_loss: 2.2245 - val_acc: 0.5729\n",
      "Epoch 68/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.2787 - acc: 0.4757 - val_loss: 2.1640 - val_acc: 0.5721\n",
      "Epoch 69/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.2839 - acc: 0.4746 - val_loss: 2.0370 - val_acc: 0.5473\n",
      "Epoch 70/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.2879 - acc: 0.4762 - val_loss: 2.0866 - val_acc: 0.5617\n",
      "Epoch 71/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.2812 - acc: 0.4765 - val_loss: 2.2720 - val_acc: 0.5751\n",
      "Epoch 72/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.2906 - acc: 0.4730 - val_loss: 2.0096 - val_acc: 0.5312\n",
      "Epoch 73/100\n",
      "39332/39332 [==============================] - 2s 49us/step - loss: 1.2858 - acc: 0.4737 - val_loss: 2.1581 - val_acc: 0.5706\n",
      "Epoch 74/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.2907 - acc: 0.4750 - val_loss: 2.2361 - val_acc: 0.5742\n",
      "Epoch 75/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.2863 - acc: 0.4754 - val_loss: 2.0573 - val_acc: 0.5536\n",
      "Epoch 76/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.2793 - acc: 0.4761 - val_loss: 2.1456 - val_acc: 0.5692\n",
      "Epoch 77/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.2885 - acc: 0.4764 - val_loss: 2.0248 - val_acc: 0.5333\n",
      "Epoch 78/100\n",
      "39332/39332 [==============================] - 2s 49us/step - loss: 1.2850 - acc: 0.4756 - val_loss: 2.0815 - val_acc: 0.5599\n",
      "Epoch 79/100\n",
      "39332/39332 [==============================] - 2s 49us/step - loss: 1.2914 - acc: 0.4734 - val_loss: 2.0584 - val_acc: 0.5519\n",
      "Epoch 80/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.2886 - acc: 0.4757 - val_loss: 1.9992 - val_acc: 0.5199\n",
      "Epoch 81/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.2915 - acc: 0.4733 - val_loss: 2.0429 - val_acc: 0.5523\n",
      "Epoch 82/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.2787 - acc: 0.4782 - val_loss: 2.0082 - val_acc: 0.5144\n",
      "Epoch 83/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.2830 - acc: 0.4756 - val_loss: 2.0595 - val_acc: 0.5454\n",
      "Epoch 84/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.2783 - acc: 0.4758 - val_loss: 2.1471 - val_acc: 0.5667\n",
      "Epoch 85/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.2861 - acc: 0.4717 - val_loss: 2.5766 - val_acc: 0.5796\n",
      "Epoch 86/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.2834 - acc: 0.4769 - val_loss: 2.3480 - val_acc: 0.5733\n",
      "Epoch 87/100\n",
      "39332/39332 [==============================] - 2s 50us/step - loss: 1.2788 - acc: 0.4760 - val_loss: 2.1642 - val_acc: 0.5708\n",
      "Epoch 88/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.2788 - acc: 0.4760 - val_loss: 2.2752 - val_acc: 0.5746\n",
      "Epoch 89/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.2770 - acc: 0.4771 - val_loss: 2.4295 - val_acc: 0.5711\n",
      "Epoch 90/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.2962 - acc: 0.4710 - val_loss: 2.2019 - val_acc: 0.5708\n",
      "Epoch 91/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.2818 - acc: 0.4756 - val_loss: 2.1881 - val_acc: 0.5714\n",
      "Epoch 92/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.2805 - acc: 0.4763 - val_loss: 2.0356 - val_acc: 0.5308\n",
      "Epoch 93/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.2786 - acc: 0.4755 - val_loss: 2.1341 - val_acc: 0.5621\n",
      "Epoch 94/100\n",
      "39332/39332 [==============================] - 2s 49us/step - loss: 1.2806 - acc: 0.4755 - val_loss: 2.0623 - val_acc: 0.5474\n",
      "Epoch 95/100\n",
      "39332/39332 [==============================] - 2s 49us/step - loss: 1.2757 - acc: 0.4769 - val_loss: 2.2290 - val_acc: 0.5703\n",
      "Epoch 96/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.2830 - acc: 0.4749 - val_loss: 2.2063 - val_acc: 0.5712\n",
      "Epoch 97/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.2879 - acc: 0.4737 - val_loss: 2.5069 - val_acc: 0.5695\n",
      "Epoch 98/100\n",
      "39332/39332 [==============================] - 2s 46us/step - loss: 1.2885 - acc: 0.4737 - val_loss: 2.3312 - val_acc: 0.5753\n",
      "Epoch 99/100\n",
      "39332/39332 [==============================] - 2s 47us/step - loss: 1.2781 - acc: 0.4763 - val_loss: 2.0570 - val_acc: 0.5387\n",
      "Epoch 100/100\n",
      "39332/39332 [==============================] - 2s 48us/step - loss: 1.2821 - acc: 0.4740 - val_loss: 2.1200 - val_acc: 0.5632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f000cb63ac8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# build the model\n",
    "model1 = baseline_model1()\n",
    "# Fit the model\n",
    "model1.fit(processed_train1, y_tr1, validation_data=(processed_train, y_tr), epochs=100, batch_size=128, verbose=1)\n",
    "# Final evaluation of the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39332/39332 [==============================] - 2s 49us/step\n",
      "22933/22933 [==============================] - 1s 45us/step\n",
      "* Accuracy on training set: 48.55%\n",
      "* Accuracy on test set: 56.32%\n"
     ]
    }
   ],
   "source": [
    "#32 output dim new\n",
    "#CORAL\n",
    "# acc 47.72\n",
    "scores_train = model1.evaluate(processed_train1, y_tr1, verbose=1)\n",
    "scores_test = model1.evaluate(processed_test, y_te, verbose=1)\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * scores_train[1]))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * scores_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
